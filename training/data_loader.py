"""
Data Loader - –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è

Wrapper –¥–ª—è UnifiedBinanceLoader –∑ –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º–∏ —Ñ—É–Ω–∫—Ü—ñ—è–º–∏:
- –ö–µ—à—É–≤–∞–Ω–Ω—è
- –í–∞–ª—ñ–¥–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –ø–æ–º–∏–ª–æ–∫
"""

import asyncio
import logging
import pandas as pd
from typing import Optional
from pathlib import Path
import sys

# –î–æ–¥–∞—î–º–æ –±–∞—Ç—å–∫—ñ–≤—Å—å–∫—É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é
sys.path.insert(0, str(Path(__file__).parent.parent))

from unified_binance_loader import UnifiedBinanceLoader

logger = logging.getLogger(__name__)


class DataLoader:
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É–≤–∞—á –¥–∞–Ω–∏—Ö –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
    
    –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
        loader = DataLoader()
        df = await loader.load('BTCUSDT', '1h', days=365)
        await loader.close()
    """
    
    def __init__(
        self,
        cache_dir: Optional[str] = None,
        use_cache: bool = False
    ):
        """
        Args:
            cache_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è
            use_cache: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –∫–µ—à
        """
        self.cache_dir = Path(cache_dir) if cache_dir else None
        self.use_cache = use_cache
        self.loader = None
        
        if self.use_cache and self.cache_dir:
            self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    async def load(
        self,
        symbol: str,
        interval: str = '1h',
        days: int = 365,
        force_reload: bool = False
    ) -> pd.DataFrame:
        """
        –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
        
        Args:
            symbol: –°–∏–º–≤–æ–ª (BTCUSDT)
            interval: –Ü–Ω—Ç–µ—Ä–≤–∞–ª (1h, 4h, 1d)
            days: –ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥–Ω—ñ–≤
            force_reload: –ü—Ä–∏–º—É—Å–æ–≤–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è (—ñ–≥–Ω–æ—Ä—É–≤–∞—Ç–∏ –∫–µ—à)
        
        Returns:
            DataFrame –∑ OHLCV –¥–∞–Ω–∏–º–∏
        """
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–µ—à—É
        if self.use_cache and not force_reload:
            cached_data = self._load_from_cache(symbol, interval, days)
            if cached_data is not None:
                logger.info(f"‚úÖ –î–∞–Ω—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑ –∫–µ—à—É: {symbol} {interval}")
                return cached_data
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ Binance
        logger.info(f"üìä –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ Binance: {symbol} {interval}, {days} –¥–Ω—ñ–≤")
        
        if self.loader is None:
            self.loader = UnifiedBinanceLoader(use_public_data=True)
        
        df = await self.loader.get_historical_data(
            symbol=symbol,
            interval=interval,
            days_back=days
        )
        
        # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
        if df is None or len(df) == 0:
            raise ValueError(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ –¥–ª—è {symbol}")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_columns = ['open', 'high', 'low', 'close', 'volume']
        missing = [col for col in required_columns if col not in df.columns]
        if missing:
            raise ValueError(f"–í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {missing}")
        
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –∫–µ—à
        if self.use_cache:
            self._save_to_cache(df, symbol, interval, days)
        
        logger.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å—ñ–≤")
        return df
    
    def _get_cache_path(self, symbol: str, interval: str, days: int) -> Path:
        """–®–ª—è—Ö –¥–æ –∫–µ—à —Ñ–∞–π–ª—É"""
        filename = f"{symbol}_{interval}_{days}d.parquet"
        return self.cache_dir / filename
    
    def _load_from_cache(
        self,
        symbol: str,
        interval: str,
        days: int
    ) -> Optional[pd.DataFrame]:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ –∫–µ—à—É"""
        if not self.cache_dir:
            return None
        
        cache_path = self._get_cache_path(symbol, interval, days)
        
        if cache_path.exists():
            try:
                df = pd.read_parquet(cache_path)
                return df
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è –∫–µ—à—É: {e}")
                return None
        
        return None
    
    def _save_to_cache(
        self,
        df: pd.DataFrame,
        symbol: str,
        interval: str,
        days: int
    ):
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –∫–µ—à"""
        if not self.cache_dir:
            return
        
        cache_path = self._get_cache_path(symbol, interval, days)
        
        try:
            df.to_parquet(cache_path)
            logger.info(f"üíæ –î–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ –∫–µ—à: {cache_path.name}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∫–µ—à—É: {e}")
    
    def clear_cache(self):
        """–û—á–∏—Å—Ç–∏—Ç–∏ –∫–µ—à"""
        if self.cache_dir and self.cache_dir.exists():
            for file in self.cache_dir.glob("*.parquet"):
                file.unlink()
            logger.info("üóëÔ∏è –ö–µ—à –æ—á–∏—â–µ–Ω–æ")
    
    async def close(self):
        """–ó–∞–∫—Ä–∏—Ç–∏ –∑'—î–¥–Ω–∞–Ω–Ω—è"""
        if self.loader:
            await self.loader.close()
            self.loader = None


# –î–æ–ø–æ–º—ñ–∂–Ω–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è
def load_data_sync(
    symbol: str,
    interval: str = '1h',
    days: int = 365,
    **kwargs
) -> pd.DataFrame:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ –æ–±–≥–æ—Ä—Ç–∫–∞ –¥–ª—è load()
    
    –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
        df = load_data_sync('BTCUSDT', '1h', days=365)
    """
    async def _load():
        loader = DataLoader(**kwargs)
        try:
            return await loader.load(symbol, interval, days)
        finally:
            await loader.close()
    
    return asyncio.run(_load())
