# -*- coding: utf-8 -*-
"""
GPU ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ Ñ‚Ð° ÑƒÑ‚Ð¸Ð»Ñ–Ñ‚Ð¸
"""
from __future__ import annotations

import logging
from typing import Optional

import tensorflow as tf

logger = logging.getLogger(__name__)


def _format_cuda_version(raw_version: int) -> str:
    """ÐŸÐµÑ€ÐµÑ‚Ð²Ð¾Ñ€ÑŽÑ” Ð²ÐµÑ€ÑÑ–ÑŽ CUDA Ð· NVML (Ð½Ð°Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´, 12020) Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ X.Y"""
    major = raw_version // 1000
    minor = (raw_version % 1000) // 10
    return f"{major}.{minor}"


def _reset_to_cpu_policy(enable_logging: bool = True) -> None:
    """Ð¡ÐºÐ¸Ð´Ð°Ñ” mixed precision Ð´Ð¾ float32 Ð´Ð»Ñ ÑÑ‚Ð°Ð±Ñ–Ð»ÑŒÐ½Ð¾Ñ— Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸ Ð½Ð° CPU."""
    try:
        from tensorflow import keras

        current_policy = keras.mixed_precision.global_policy().name
        if current_policy != 'float32':
            keras.mixed_precision.set_global_policy('float32')
            if enable_logging:
                logger.info("â„¹ï¸ Mixed precision Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾ Ð´Ð»Ñ CPU Ñ€ÐµÐ¶Ð¸Ð¼Ñƒ")
    except Exception as err:  # pragma: no cover - Ð¿Ð¾Ð»Ñ–Ñ‚Ð¸ÐºÐ¸ Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð±ÑƒÑ‚Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¼Ð¸ Ñƒ Ñ‚ÐµÑÑ‚Ð°Ñ…
        logger.debug("ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ ÑÐºÐ¸Ð½ÑƒÑ‚Ð¸ mixed precision: %s", err)


def _log_gpu_environment_diagnostics(reason: str, error: Optional[Exception] = None) -> None:
    """Ð’Ð¸Ð²Ð¾Ð´Ð¸Ñ‚ÑŒ Ð´Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ñƒ Ð´Ñ–Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÑƒ, ÑÐºÑ‰Ð¾ TensorFlow Ð½Ðµ Ð¼Ð¾Ð¶Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ GPU."""
    logger.warning("âš ï¸ TensorFlow Ð½Ðµ Ð¼Ð¾Ð¶Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ñ‚Ð¸ GPU (%s)", reason)
    if error is not None:
        logger.warning("   â†³ %s", error)

    try:
        import pynvml

        pynvml.nvmlInit()
        try:
            driver_version = pynvml.nvmlSystemGetDriverVersion()
            if isinstance(driver_version, bytes):
                driver_version = driver_version.decode('utf-8')

            device_count = pynvml.nvmlDeviceGetCount()
            logger.warning("ðŸ§© NVML: Ð²Ð¸ÑÐ²Ð»ÐµÐ½Ð¾ %d GPU, Ð´Ñ€Ð°Ð¹Ð²ÐµÑ€ %s", device_count, driver_version)

            cuda_driver_version = None
            if hasattr(pynvml, "nvmlSystemGetCudaDriverVersion_v2"):
                cuda_driver_version = pynvml.nvmlSystemGetCudaDriverVersion_v2()
            elif hasattr(pynvml, "nvmlSystemGetCudaDriverVersion"):
                cuda_driver_version = pynvml.nvmlSystemGetCudaDriverVersion()

            if cuda_driver_version:
                logger.warning(
                    "ðŸ§© NVML: Ð²ÐµÑ€ÑÑ–Ñ CUDA Ð´Ñ€Ð°Ð¹Ð²ÐµÑ€Ð° %s",
                    _format_cuda_version(cuda_driver_version),
                )

            for index in range(device_count):
                handle = pynvml.nvmlDeviceGetHandleByIndex(index)
                name = pynvml.nvmlDeviceGetName(handle)
                if isinstance(name, bytes):
                    name = name.decode('utf-8')
                memory = pynvml.nvmlDeviceGetMemoryInfo(handle)
                logger.info(
                    "   â€¢ GPU %d: %s, Ð¿Ð°Ð¼'ÑÑ‚ÑŒ %.0f / %.0f MB",
                    index,
                    name,
                    memory.used / (1024 ** 2),
                    memory.total / (1024 ** 2),
                )
        finally:  # pragma: no cover - nvmlShutdown Ð¼Ð¾Ð¶Ðµ Ð½Ðµ Ð±ÑƒÑ‚Ð¸ Ð²Ð¸ÐºÐ»Ð¸ÐºÐ°Ð½Ð¾ Ñƒ Ð¼Ð¾ÐºÐ¾Ð²Ð°Ð½Ð¾Ð¼Ñƒ ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ñ–
            try:
                pynvml.nvmlShutdown()
            except Exception:
                pass
    except ImportError:
        logger.warning("pynvml Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°Ñ”Ð¼Ð¾ NVML Ð´Ñ–Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÑƒ")
    except Exception as nvml_error:
        logger.warning("ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð·Ñ–Ð±Ñ€Ð°Ñ‚Ð¸ NVML Ð´Ñ–Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÑƒ: %s", nvml_error)

    try:
        build_info = tf.sysconfig.get_build_info()
        logger.warning(
            "â„¹ï¸ TensorFlow Ð·Ñ–Ð±Ñ€Ð°Ð½Ð¾ Ð· CUDA %s / cuDNN %s",
            build_info.get('cuda_version', 'Ð½ÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¾'),
            build_info.get('cudnn_version', 'Ð½ÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¾'),
        )
    except Exception as build_error:
        logger.debug("ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð·Ñ‡Ð¸Ñ‚Ð°Ñ‚Ð¸ TensorFlow build info: %s", build_error)

    logger.warning(
        "ðŸ’¡ ÐŸÐµÑ€ÐµÐºÐ¾Ð½Ð°Ð¹Ñ‚ÐµÑÑŒ, Ñ‰Ð¾ Ð²ÐµÑ€ÑÑ–Ñ Ð´Ñ€Ð°Ð¹Ð²ÐµÑ€Ð° NVIDIA ÑÑƒÐ¼Ñ–ÑÐ½Ð° Ð· TensorFlow Ñ‚Ð° CUDA. "
        "ÐžÐ½Ð¾Ð²Ñ–Ñ‚ÑŒ Ð´Ñ€Ð°Ð¹Ð²ÐµÑ€ Ð°Ð±Ð¾ Ð²ÑÑ‚Ð°Ð½Ð¾Ð²Ñ–Ñ‚ÑŒ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ð¸Ð¹ Ð¿Ð°ÐºÐµÑ‚ CUDA, Ð¿Ð¾Ñ‚Ñ–Ð¼ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÑ‚Ñ–Ñ‚ÑŒ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ."
    )


def configure_gpu(
    use_mixed_precision: bool = True,
    use_xla: bool = True,
    memory_growth: bool = True,
) -> bool:
    """ÐžÐ¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ðµ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ GPU"""

    try:
        gpus = tf.config.experimental.list_physical_devices('GPU')
    except Exception as error:
        _log_gpu_environment_diagnostics('list_physical_devices', error)
        _reset_to_cpu_policy(enable_logging=use_mixed_precision)
        return False

    if not gpus:
        _log_gpu_environment_diagnostics('TensorFlow Ð½Ðµ Ð²Ð¸ÑÐ²Ð¸Ð² ÑÑƒÐ¼Ñ–ÑÐ½Ð¸Ñ… GPU')
        _reset_to_cpu_policy(enable_logging=use_mixed_precision)
        return False

    try:
        tf.config.set_visible_devices(gpus, 'GPU')
        if memory_growth:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)

        if use_xla:
            try:
                tf.config.optimizer.set_jit(True)
                logger.info("âœ… XLA JIT ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾")
            except Exception as jit_error:
                logger.warning("âš ï¸ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ ÑƒÐ²Ñ–Ð¼ÐºÐ½ÑƒÑ‚Ð¸ XLA JIT: %s", jit_error)

        if use_mixed_precision:
            from tensorflow import keras

            keras.mixed_precision.set_global_policy('mixed_float16')
            logger.info("âœ… Mixed precision ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾")

        logger.info("âœ… GPU Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹: %d Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ð¾Ñ—Ð²", len(gpus))
        return True
    except Exception as error:
        _log_gpu_environment_diagnostics('configure_gpu', error)
        _reset_to_cpu_policy(enable_logging=use_mixed_precision)
        return False


def get_gpu_info() -> dict:
    """ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ð½Ð½Ñ Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ— Ð¿Ñ€Ð¾ GPU"""

    info: dict = {
        'available': False,
        'count': 0,
        'details': [],
    }

    try:
        import pynvml

        pynvml.nvmlInit()
        try:
            driver_version = pynvml.nvmlSystemGetDriverVersion()
            if isinstance(driver_version, bytes):
                driver_version = driver_version.decode('utf-8')
            info['driver_version'] = driver_version

            device_count = pynvml.nvmlDeviceGetCount()
            info['count'] = device_count
            info['available'] = device_count > 0

            if hasattr(pynvml, "nvmlSystemGetCudaDriverVersion_v2"):
                cuda_driver_version = pynvml.nvmlSystemGetCudaDriverVersion_v2()
            elif hasattr(pynvml, "nvmlSystemGetCudaDriverVersion"):
                cuda_driver_version = pynvml.nvmlSystemGetCudaDriverVersion()
            else:
                cuda_driver_version = None

            if cuda_driver_version:
                info['cuda_driver_version'] = _format_cuda_version(cuda_driver_version)

            details = []
            for index in range(device_count):
                handle = pynvml.nvmlDeviceGetHandleByIndex(index)
                name = pynvml.nvmlDeviceGetName(handle)
                if isinstance(name, bytes):
                    name = name.decode('utf-8')
                memory = pynvml.nvmlDeviceGetMemoryInfo(handle)
                utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)

                details.append({
                    'id': index,
                    'name': name,
                    'memory_used_mb': memory.used / (1024 ** 2),
                    'memory_total_mb': memory.total / (1024 ** 2),
                    'memory_percent': (memory.used / memory.total) * 100 if memory.total else 0,
                    'gpu_utilization': utilization.gpu,
                    'memory_utilization': utilization.memory,
                })

            info['details'] = details
        finally:
            try:
                pynvml.nvmlShutdown()
            except Exception:
                pass
    except ImportError:
        info['error'] = 'pynvml_not_installed'
    except Exception as error:
        info['error'] = str(error)

    try:
        tf_gpus = tf.config.experimental.list_physical_devices('GPU')
        info['tensorflow_visible'] = len(tf_gpus)
    except Exception as error:
        info['tensorflow_error'] = str(error)

    return info