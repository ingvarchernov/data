# -*- coding: utf-8 -*-
"""
–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∫–µ—à—É–≤–∞–Ω–Ω—è –∑ Redis —Ç–∞ memory cache
–ü—ñ–¥—Ç—Ä–∏–º—É—î —Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—é, TTL, –ø–∞—Ç–µ—Ä–Ω–∏ –∫–ª—é—á—ñ–≤ —Ç–∞ –º–µ—Ç—Ä–∏–∫–∏
"""
import asyncio
import logging
import pickle
import hashlib
import json
import time
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Union, Callable
from dataclasses import dataclass, asdict
from functools import wraps

import redis
import redis.asyncio as aioredis
import pandas as pd
import numpy as np
from cachetools import TTLCache, LRUCache

logger = logging.getLogger(__name__)

@dataclass
class CacheStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–µ—à—É–≤–∞–Ω–Ω—è"""
    hits: int = 0
    misses: int = 0
    sets: int = 0
    deletes: int = 0
    errors: int = 0
    
    @property
    def hit_rate(self) -> float:
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0.0
    
    def to_dict(self) -> Dict:
        return asdict(self)

class SmartSerializer:
    """–†–æ–∑—É–º–Ω–∏–π —Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ç–æ—Ä –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ –¥–∞–Ω–∏—Ö"""
    
    @staticmethod
    def serialize(data: Any) -> bytes:
        """–°–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö"""
        try:
            if isinstance(data, pd.DataFrame):
                return pickle.dumps({
                    'type': 'dataframe',
                    'data': data.to_dict('records'),
                    'index': data.index.tolist(),
                    'columns': data.columns.tolist()
                })
            elif isinstance(data, pd.Series):
                return pickle.dumps({
                    'type': 'series',
                    'data': data.to_dict(),
                    'name': data.name
                })
            elif isinstance(data, np.ndarray):
                return pickle.dumps({
                    'type': 'numpy',
                    'data': data.tolist(),
                    'shape': data.shape,
                    'dtype': str(data.dtype)
                })
            elif isinstance(data, (dict, list, str, int, float, bool)):
                return pickle.dumps({
                    'type': 'simple',
                    'data': data
                })
            else:
                return pickle.dumps({
                    'type': 'complex',
                    'data': data
                })
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó: {e}")
            raise
    
    @staticmethod
    def deserialize(data: bytes) -> Any:
        """–î–µ—Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö"""
        try:
            obj = pickle.loads(data)
            
            if obj['type'] == 'dataframe':
                df = pd.DataFrame(obj['data'])
                if obj['index']:
                    df.index = obj['index']
                return df
            elif obj['type'] == 'series':
                return pd.Series(obj['data'], name=obj['name'])
            elif obj['type'] == 'numpy':
                return np.array(obj['data'], dtype=obj['dtype']).reshape(obj['shape'])
            elif obj['type'] in ['simple', 'complex']:
                return obj['data']
            else:
                return obj['data']
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –¥–µ—Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó: {e}")
            raise

class AdvancedCacheManager:
    """–†–æ–∑—à–∏—Ä–µ–Ω–∏–π –º–µ–Ω–µ–¥–∂–µ—Ä –∫–µ—à—É–≤–∞–Ω–Ω—è"""
    
    def __init__(self,
                 redis_url: str = "redis://localhost:6379",
                 memory_cache_size: int = 1000,
                 default_ttl: int = 3600,
                 use_redis: bool = True,
                 use_memory: bool = True,
                 key_prefix: str = "crypto_ml"):
        
        self.redis_url = redis_url
        self.default_ttl = default_ttl
        self.use_redis = use_redis
        self.use_memory = use_memory
        self.key_prefix = key_prefix
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = CacheStats()
        
        # Memory cache
        if use_memory:
            self.memory_cache = TTLCache(maxsize=memory_cache_size, ttl=default_ttl)
            self.lru_cache = LRUCache(maxsize=memory_cache_size // 2)
        
        # Redis connection
        self.redis_client = None
        self.async_redis = None
        
        if use_redis:
            self._init_redis()
    
    def _init_redis(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è Redis"""
        try:
            self.redis_client = redis.from_url(
                self.redis_url,
                socket_connect_timeout=5,
                socket_timeout=5,
                retry_on_timeout=True,
                health_check_interval=30
            )
            
            # –¢–µ—Å—Ç—É—î–º–æ –∑'—î–¥–Ω–∞–Ω–Ω—è
            self.redis_client.ping()
            logger.info("‚úÖ Redis –ø—ñ–¥–∫–ª—é—á–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Redis –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ memory cache: {e}")
            self.use_redis = False
    
    async def _get_async_redis(self):
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ Redis –∫–ª—ñ—î–Ω—Ç–∞"""
        if not self.async_redis:
            try:
                self.async_redis = aioredis.from_url(self.redis_url)
                await self.async_redis.ping()
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Async Redis –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π: {e}")
                return None
        return self.async_redis
    
    def _generate_key(self, key: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø–æ–≤–Ω–æ–≥–æ –∫–ª—é—á–∞ –∑ –ø—Ä–µ—Ñ—ñ–∫—Å–æ–º"""
        return f"{self.key_prefix}:{key}"
    
    def _hash_key(self, data: Any) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ö–µ—à–∞ –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –∫–ª—é—á—ñ–≤"""
        if isinstance(data, (dict, list)):
            data_str = json.dumps(data, sort_keys=True)
        else:
            data_str = str(data)
        return hashlib.md5(data_str.encode()).hexdigest()
    
    def get(self, key: str, default: Any = None) -> Any:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–µ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –∑ –∫–µ—à—É"""
        full_key = self._generate_key(key)
        
        # –°–ø–æ—á–∞—Ç–∫—É memory cache
        if self.use_memory and full_key in self.memory_cache:
            self.stats.hits += 1
            return self.memory_cache[full_key]
        
        # –ü–æ—Ç—ñ–º LRU cache
        if self.use_memory and full_key in self.lru_cache:
            value = self.lru_cache[full_key]
            # –ü–µ—Ä–µ–º—ñ—â—É—î–º–æ –≤ TTL cache
            self.memory_cache[full_key] = value
            self.stats.hits += 1
            return value
        
        # –ü–æ—Ç—ñ–º Redis
        if self.use_redis and self.redis_client:
            try:
                data = self.redis_client.get(full_key)
                if data:
                    value = SmartSerializer.deserialize(data)
                    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ memory cache
                    if self.use_memory:
                        self.memory_cache[full_key] = value
                    self.stats.hits += 1
                    return value
            except Exception as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è –∑ Redis: {e}")
                self.stats.errors += 1
        
        self.stats.misses += 1
        return default
    
    async def get_async(self, key: str, default: Any = None) -> Any:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–µ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –∑ –∫–µ—à—É"""
        full_key = self._generate_key(key)
        
        # Memory cache
        if self.use_memory and full_key in self.memory_cache:
            self.stats.hits += 1
            return self.memory_cache[full_key]
        
        # Redis
        if self.use_redis:
            try:
                redis_client = await self._get_async_redis()
                if redis_client:
                    data = await redis_client.get(full_key)
                    if data:
                        value = SmartSerializer.deserialize(data)
                        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ memory cache
                        if self.use_memory:
                            self.memory_cache[full_key] = value
                        self.stats.hits += 1
                        return value
            except Exception as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ —á–∏—Ç–∞–Ω–Ω—è –∑ Redis: {e}")
                self.stats.errors += 1
        
        self.stats.misses += 1
        return default
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –∫–µ—à"""
        full_key = self._generate_key(key)
        ttl = ttl or self.default_ttl
        
        try:
            # Memory cache
            if self.use_memory:
                self.memory_cache[full_key] = value
                self.lru_cache[full_key] = value
            
            # Redis
            if self.use_redis and self.redis_client:
                serialized_data = SmartSerializer.serialize(value)
                self.redis_client.setex(full_key, ttl, serialized_data)
            
            self.stats.sets += 1
            return True
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –∫–µ—à: {e}")
            self.stats.errors += 1
            return False
    
    async def set_async(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –∫–µ—à"""
        full_key = self._generate_key(key)
        ttl = ttl or self.default_ttl
        
        try:
            # Memory cache
            if self.use_memory:
                self.memory_cache[full_key] = value
            
            # Redis
            if self.use_redis:
                redis_client = await self._get_async_redis()
                if redis_client:
                    serialized_data = SmartSerializer.serialize(value)
                    await redis_client.setex(full_key, ttl, serialized_data)
            
            self.stats.sets += 1
            return True
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –∫–µ—à: {e}")
            self.stats.errors += 1
            return False
    
    def delete(self, key: str) -> bool:
        """–í–∏–¥–∞–ª–µ–Ω–Ω—è –∑ –∫–µ—à—É"""
        full_key = self._generate_key(key)
        
        try:
            # Memory cache
            if self.use_memory:
                self.memory_cache.pop(full_key, None)
                self.lru_cache.pop(full_key, None)
            
            # Redis
            if self.use_redis and self.redis_client:
                self.redis_client.delete(full_key)
            
            self.stats.deletes += 1
            return True
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏–¥–∞–ª–µ–Ω–Ω—è –∑ –∫–µ—à—É: {e}")
            self.stats.errors += 1
            return False
    
    def delete_pattern(self, pattern: str) -> int:
        """–í–∏–¥–∞–ª–µ–Ω–Ω—è –∑–∞ –ø–∞—Ç–µ—Ä–Ω–æ–º"""
        deleted_count = 0
        full_pattern = self._generate_key(pattern)
        
        try:
            # Memory cache (–≤–∏–¥–∞–ª—è—î–º–æ –≤—Å—ñ –∫–ª—é—á—ñ —â–æ –ø–æ—á–∏–Ω–∞—é—Ç—å—Å—è –∑ –ø–∞—Ç–µ—Ä–Ω—É)
            if self.use_memory:
                keys_to_delete = [k for k in self.memory_cache.keys() if k.startswith(full_pattern.replace('*', ''))]
                for key in keys_to_delete:
                    self.memory_cache.pop(key, None)
                    self.lru_cache.pop(key, None)
                deleted_count += len(keys_to_delete)
            
            # Redis
            if self.use_redis and self.redis_client:
                keys = self.redis_client.keys(full_pattern)
                if keys:
                    self.redis_client.delete(*keys)
                    deleted_count += len(keys)
            
            logger.info(f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ {deleted_count} –∫–ª—é—á—ñ–≤ –∑–∞ –ø–∞—Ç–µ—Ä–Ω–æ–º {pattern}")
            return deleted_count
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏–¥–∞–ª–µ–Ω–Ω—è –∑–∞ –ø–∞—Ç–µ—Ä–Ω–æ–º: {e}")
            return 0
    
    def invalidate_by_tags(self, tags: List[str]) -> int:
        """–Ü–Ω–≤–∞–ª—ñ–¥–∞—Ü—ñ—è –∫–µ—à—É –∑–∞ —Ç–µ–≥–∞–º–∏"""
        deleted_count = 0
        for tag in tags:
            deleted_count += self.delete_pattern(f"*{tag}*")
        return deleted_count
    
    def cache_decorator(self, ttl: Optional[int] = None, key_func: Optional[Callable] = None):
        """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ–π"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∫–ª—é—á–∞
                if key_func:
                    cache_key = key_func(*args, **kwargs)
                else:
                    cache_key = f"{func.__name__}:{self._hash_key({'args': args, 'kwargs': kwargs})}"
                
                # –°–ø—Ä–æ–±–∞ –æ—Ç—Ä–∏–º–∞—Ç–∏ –∑ –∫–µ—à—É
                result = self.get(cache_key)
                if result is not None:
                    return result
                
                # –í–∏–∫–æ–Ω—É—î–º–æ —Ñ—É–Ω–∫—Ü—ñ—é
                result = func(*args, **kwargs)
                
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ –∫–µ—à
                self.set(cache_key, result, ttl)
                
                return result
            return wrapper
        return decorator
    
    def async_cache_decorator(self, ttl: Optional[int] = None, key_func: Optional[Callable] = None):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∏–π –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è"""
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∫–ª—é—á–∞
                if key_func:
                    cache_key = key_func(*args, **kwargs)
                else:
                    cache_key = f"{func.__name__}:{self._hash_key({'args': args, 'kwargs': kwargs})}"
                
                # –°–ø—Ä–æ–±–∞ –æ—Ç—Ä–∏–º–∞—Ç–∏ –∑ –∫–µ—à—É
                result = await self.get_async(cache_key)
                if result is not None:
                    return result
                
                # –í–∏–∫–æ–Ω—É—î–º–æ —Ñ—É–Ω–∫—Ü—ñ—é
                result = await func(*args, **kwargs)
                
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ –∫–µ—à
                await self.set_async(cache_key, result, ttl)
                
                return result
            return wrapper
        return decorator
    
    def get_stats(self) -> Dict:
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–µ—à—É–≤–∞–Ω–Ω—è"""
        stats = self.stats.to_dict()
        
        if self.use_memory:
            stats['memory_cache_size'] = len(self.memory_cache)
            stats['lru_cache_size'] = len(self.lru_cache)
        
        if self.use_redis and self.redis_client:
            try:
                redis_info = self.redis_client.info('memory')
                stats['redis_memory_used'] = redis_info.get('used_memory_human', 'N/A')
                stats['redis_keys'] = self.redis_client.dbsize()
            except Exception as e:
                logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ Redis: {e}")
        
        return stats
    
    def clear_all(self):
        """–û—á–∏—â–µ–Ω–Ω—è –≤—Å—å–æ–≥–æ –∫–µ—à—É"""
        if self.use_memory:
            self.memory_cache.clear()
            self.lru_cache.clear()
        
        if self.use_redis and self.redis_client:
            pattern = self._generate_key("*")
            keys = self.redis_client.keys(pattern)
            if keys:
                self.redis_client.delete(*keys)
        
        logger.info("üóëÔ∏è –í–µ—Å—å –∫–µ—à –æ—á–∏—â–µ–Ω–æ")
    
    def warmup_cache(self, data_dict: Dict[str, Any], ttl: Optional[int] = None):
        """–ü–æ–ø–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–µ—à—É"""
        logger.info(f"üî• –ü–æ–ø–µ—Ä–µ–¥–Ω—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è {len(data_dict)} –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ –≤ –∫–µ—à")
        
        for key, value in data_dict.items():
            self.set(key, value, ttl)
        
        logger.info("‚úÖ –ö–µ—à –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ")

# –ì–ª–æ–±–∞–ª—å–Ω–∏–π –º–µ–Ω–µ–¥–∂–µ—Ä –∫–µ—à—É
cache_manager = AdvancedCacheManager()

# –ó—Ä—É—á–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó
def cache_get(key: str, default: Any = None) -> Any:
    """–®–≤–∏–¥–∫–µ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –∑ –∫–µ—à—É"""
    return cache_manager.get(key, default)

def cache_set(key: str, value: Any, ttl: Optional[int] = None) -> bool:
    """–®–≤–∏–¥–∫–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –∫–µ—à"""
    return cache_manager.set(key, value, ttl)

def cache_delete(key: str) -> bool:
    """–®–≤–∏–¥–∫–µ –≤–∏–¥–∞–ª–µ–Ω–Ω—è –∑ –∫–µ—à—É"""
    return cache_manager.delete(key)

def cached(ttl: Optional[int] = None, key_func: Optional[Callable] = None):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –∫–µ—à—É–≤–∞–Ω–Ω—è"""
    return cache_manager.cache_decorator(ttl, key_func)

def async_cached(ttl: Optional[int] = None, key_func: Optional[Callable] = None):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∏–π –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –∫–µ—à—É–≤–∞–Ω–Ω—è"""
    return cache_manager.async_cache_decorator(ttl, key_func)

# –°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –¥–ª—è ML
def cache_model_prediction(symbol: str, interval: str, model_hash: str, prediction: Any, ttl: int = 1800):
    """–ö–µ—à—É–≤–∞–Ω–Ω—è –ø—Ä–æ–≥–Ω–æ–∑—É –º–æ–¥–µ–ª—ñ"""
    key = f"model_pred:{symbol}:{interval}:{model_hash}"
    return cache_set(key, prediction, ttl)

def get_cached_model_prediction(symbol: str, interval: str, model_hash: str) -> Any:
    """–û—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–µ—à–æ–≤–∞–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑—É"""
    key = f"model_pred:{symbol}:{interval}:{model_hash}"
    return cache_get(key)

def cache_indicators(symbol: str, interval: str, indicators: Dict, ttl: int = 3600):
    """–ö–µ—à—É–≤–∞–Ω–Ω—è —Ç–µ—Ö–Ω—ñ—á–Ω–∏—Ö —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤"""
    key = f"indicators:{symbol}:{interval}"
    return cache_set(key, indicators, ttl)

def get_cached_indicators(symbol: str, interval: str) -> Optional[Dict]:
    """–û—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–µ—à–æ–≤–∞–Ω–∏—Ö —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤"""
    key = f"indicators:{symbol}:{interval}"
    return cache_get(key)

def invalidate_symbol_cache(symbol: str):
    """–Ü–Ω–≤–∞–ª—ñ–¥–∞—Ü—ñ—è –≤—Å—å–æ–≥–æ –∫–µ—à—É –¥–ª—è —Å–∏–º–≤–æ–ª—É"""
    cache_manager.delete_pattern(f"*{symbol}*")

def get_cache_info() -> Dict:
    """–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –∫–µ—à"""
    return cache_manager.get_stats()