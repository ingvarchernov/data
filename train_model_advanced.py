#!/usr/bin/env python3
"""
–ü–æ–∫—Ä–∞—â–µ–Ω–∏–π —Å–∫—Ä–∏–ø—Ç —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∑ —Ä–æ–∑—à–∏—Ä–µ–Ω–∏–º–∏ —Ñ—ñ—á–∞–º–∏ –¥–ª—è –¥–æ—Å—è–≥–Ω–µ–Ω–Ω—è 60-70% accuracy
"""

import os
import sys
import asyncio
import logging
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Tuple
import tensorflow as tf
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import TimeSeriesSplit
import joblib

# –õ–æ–∫–∞–ª—å–Ω—ñ —ñ–º–ø–æ—Ä—Ç–∏
from gpu_config import configure_gpu
from optimized_model import OptimizedPricePredictionModel
from optimized_indicators import calculate_all_indicators
from intelligent_sys import UnifiedBinanceLoader
from advanced_training_config import (
    DATA_CONFIG, 
    SYMBOL_CONFIGS, 
    MODEL_ARCHITECTURES,
    TRAINING_IMPROVEMENTS
)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

configure_gpu()

SYMBOLS = ['BTCUSDT', 'ETHUSDT', 'ADAUSDT', 'SOLUSDT', 'AVAXUSDT', 'DOTUSDT', 'LINKUSDT']
INTERVAL = '1h'


class AdvancedFeatureEngineer:
    """–ü–æ–∫—Ä–∞—â–µ–Ω–∏–π feature engineering - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î Rust —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏ –¥–ª—è —à–≤–∏–¥–∫–æ–¥—ñ—ó"""
    
    def __init__(self):
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å Rust –º–æ–¥—É–ª—è
        try:
            import fast_indicators
            self.rust_available = True
            self.fast_indicators = fast_indicators
            logger.info("‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ Rust —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏ –¥–ª—è —à–≤–∏–¥–∫–æ–¥—ñ—ó")
        except ImportError:
            self.rust_available = False
            logger.warning("‚ö†Ô∏è Rust –º–æ–¥—É–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è Python")
    
    def add_rust_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """–î–æ–¥–∞—î —Ä–æ–∑—à–∏—Ä–µ–Ω—ñ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏ —á–µ—Ä–µ–∑ Rust (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π)"""
        if not self.rust_available:
            logger.warning("Rust –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π, –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Ä–æ–∑—à–∏—Ä–µ–Ω—ñ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏")
            return df
        
        try:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ—Å–Ω—É—é—á—ñ Rust —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏
            prices = df['close'].values
            high = df['high'].values
            low = df['low'].values
            volume = df['volume'].values
            
            # Helper function –¥–ª—è –¥–æ–¥–∞–≤–∞–Ω–Ω—è –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—é –¥–æ–≤–∂–∏–Ω–æ—é
            def add_indicator(name, values):
                if len(values) > 0:
                    # –î–æ–¥–∞—î–º–æ NaN –Ω–∞ –ø–æ—á–∞—Ç–∫—É —â–æ–± –≤–∏—Ä—ñ–≤–Ω—è—Ç–∏ –¥–æ–≤–∂–∏–Ω—É
                    if len(values) < len(df):
                        padding = [np.nan] * (len(df) - len(values))
                        df[name] = padding + list(values)
                    else:
                        df[name] = values
            
            # RSI –∑ —Ä—ñ–∑–Ω–∏–º–∏ –ø–µ—Ä—ñ–æ–¥–∞–º–∏
            add_indicator('rsi_7', self.fast_indicators.fast_rsi(prices, 7))
            add_indicator('rsi_21', self.fast_indicators.fast_rsi(prices, 21))
            
            # MACD
            macd, signal, hist = self.fast_indicators.fast_macd(prices, 12, 26, 9)
            add_indicator('macd', macd)
            add_indicator('macd_signal', signal)
            add_indicator('macd_histogram', hist)
            
            # Bollinger Bands
            upper, lower = self.fast_indicators.fast_bollinger_bands(prices, 20, 2.0)
            add_indicator('bb_upper', upper)
            add_indicator('bb_lower', lower)
            if len(upper) > 0 and len(lower) > 0:
                add_indicator('bb_width', upper - lower)
                add_indicator('bb_percent', (prices[-len(upper):] - lower) / (upper - lower + 1e-8))
            
            # Stochastic (–ø–æ—Ç—Ä—ñ–±–µ–Ω smooth_d –ø–∞—Ä–∞–º–µ—Ç—Ä)
            try:
                stoch_k, stoch_d = self.fast_indicators.fast_stochastic(high, low, prices, 14, 3, 3)
                add_indicator('stoch_k', stoch_k)
                add_indicator('stoch_d', stoch_d)
            except:
                pass  # Stochastic –º–æ–∂–µ –Ω–µ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏
            
            # ATR –∑ —Ä—ñ–∑–Ω–∏–º–∏ –ø–µ—Ä—ñ–æ–¥–∞–º–∏
            add_indicator('atr_7', self.fast_indicators.fast_atr(high, low, prices, 7))
            add_indicator('atr_21', self.fast_indicators.fast_atr(high, low, prices, 21))
            
            # CCI
            add_indicator('cci', self.fast_indicators.fast_cci(high, low, prices, 20))
            
            # OBV (–ø–æ–≤–µ—Ä—Ç–∞—î –ø–æ–≤–Ω—É –¥–æ–≤–∂–∏–Ω—É)
            df['obv'] = self.fast_indicators.fast_obv(prices, volume)
            
            # ADX
            add_indicator('adx', self.fast_indicators.fast_adx(high, low, prices, 14))
            
            # VWAP (–ø–æ–≤–µ—Ä—Ç–∞—î –ø–æ–≤–Ω—É –¥–æ–≤–∂–∏–Ω—É)
            df['vwap'] = self.fast_indicators.fast_vwap(prices, volume, high, low)
            
            # EMA –∑ —Ä—ñ–∑–Ω–∏–º–∏ –ø–µ—Ä—ñ–æ–¥–∞–º–∏ (–ø–æ–≤–µ—Ä—Ç–∞—î –ø–æ–≤–Ω—É –¥–æ–≤–∂–∏–Ω—É)
            for period in [5, 10, 20, 50, 100, 200]:
                df[f'ema_{period}'] = self.fast_indicators.fast_ema(prices, period)
            
            logger.info(f"‚úÖ –î–æ–¥–∞–Ω–æ Rust —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏ (–≤—Å—å–æ–≥–æ {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫)")
            
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É Rust —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤: {e}")
            import traceback
            traceback.print_exc()
        
        return df
    
    @staticmethod
    def add_rolling_stats(df: pd.DataFrame, windows=[5, 10, 20, 30]) -> pd.DataFrame:
        """–î–æ–¥–∞—î rolling —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (—à–≤–∏–¥–∫—ñ pandas –æ–ø–µ—Ä–∞—Ü—ñ—ó)"""
        for window in windows:
            df[f'close_mean_{window}'] = df['close'].rolling(window).mean()
            df[f'close_std_{window}'] = df['close'].rolling(window).std()
            df[f'close_min_{window}'] = df['close'].rolling(window).min()
            df[f'close_max_{window}'] = df['close'].rolling(window).max()
            df[f'volume_mean_{window}'] = df['volume'].rolling(window).mean()
            
            # Normalized distance from rolling stats
            df[f'dist_from_mean_{window}'] = (df['close'] - df[f'close_mean_{window}']) / (df[f'close_std_{window}'] + 1e-8)
        
        return df
    
    @staticmethod
    def add_price_patterns(df: pd.DataFrame) -> pd.DataFrame:
        """–î–æ–¥–∞—î price action patterns (–ª–µ–≥–∫—ñ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è)"""
        # Higher highs / Lower lows
        df['higher_high'] = (df['high'] > df['high'].shift(1)).astype(int)
        df['lower_low'] = (df['low'] < df['low'].shift(1)).astype(int)
        
        # Breakout detection
        df['breakout_up'] = (df['close'] > df['high'].rolling(20).max().shift(1)).astype(int)
        df['breakout_down'] = (df['close'] < df['low'].rolling(20).min().shift(1)).astype(int)
        
        # Body/Wick ratios
        df['body'] = abs(df['close'] - df['open'])
        df['upper_wick'] = df['high'] - df[['open', 'close']].max(axis=1)
        df['lower_wick'] = df[['open', 'close']].min(axis=1) - df['low']
        df['body_ratio'] = df['body'] / (df['high'] - df['low'] + 1e-8)
        
        return df
    
    @staticmethod
    def add_volatility_features(df: pd.DataFrame) -> pd.DataFrame:
        """–î–æ–¥–∞—î –¥–æ–¥–∞—Ç–∫–æ–≤—ñ volatility features"""
        # Historic volatility (—Ä—ñ–∑–Ω—ñ –ø–µ—Ä—ñ–æ–¥–∏)
        for period in [10, 20, 30]:
            returns = df['close'].pct_change()
            df[f'hvol_{period}'] = returns.rolling(period).std() * np.sqrt(period)
        
        # Volatility ratio
        df['volatility_ratio'] = df['hvol_10'] / (df['hvol_30'] + 1e-8)
        
        return df
    
    @staticmethod
    def add_momentum_features(df: pd.DataFrame) -> pd.DataFrame:
        """–î–æ–¥–∞—î momentum features"""
        # Rate of Change
        for period in [5, 10, 20]:
            df[f'roc_{period}'] = df['close'].pct_change(periods=period)
        
        # Momentum
        for period in [5, 10, 20]:
            df[f'mom_{period}'] = df['close'] - df['close'].shift(period)
        
        # Acceleration (change in momentum)
        df['acceleration'] = df['mom_10'] - df['mom_10'].shift(1)
        
        # Velocity (rate of price change)
        df['velocity'] = df['close'].diff() / df['close'].shift(1)
        
        return df


class AdvancedModelTrainer:
    """–ü–æ–∫—Ä–∞—â–µ–Ω–∏–π trainer –∑ —É—Å—ñ–º–∞ –Ω–æ–≤–∏–º–∏ —Ñ—ñ—á–∞–º–∏"""
    
    def __init__(self, symbol: str, interval: str = '1h', testnet: bool = False):
        self.symbol = symbol
        self.interval = interval
        self.testnet = testnet
        
        # –û—Ç—Ä–∏–º—É—î–º–æ symbol-specific config –∞–±–æ default
        symbol_config = SYMBOL_CONFIGS.get(symbol, {})
        arch_name = symbol_config.get('architecture', 'advanced_lstm')
        self.config = MODEL_ARCHITECTURES[arch_name].copy()
        
        # –û–Ω–æ–≤–ª—é—î–º–æ —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å–∏–º–≤–æ–ª—É
        for key in ['sequence_length', 'learning_rate', 'batch_size']:
            if key in symbol_config:
                self.config[key] = symbol_config[key]
        
        self.scaler = RobustScaler()
        self.model = None
        self.history = None
        self.feature_engineer = AdvancedFeatureEngineer()
        
        logger.info(f"üìä {symbol}: {arch_name}, seq_len={self.config['sequence_length']}, "
                   f"lr={self.config['learning_rate']}, batch={self.config['batch_size']}")
    
    async def load_data(self, days: int = None) -> pd.DataFrame:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö"""
        days = days or DATA_CONFIG['days_back']
        logger.info(f"üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è {days} –¥–Ω—ñ–≤ –¥–∞–Ω–∏—Ö –¥–ª—è {self.symbol}...")
        
        from dotenv import load_dotenv
        load_dotenv()
        
        loader = UnifiedBinanceLoader(
            api_key=os.getenv('FUTURES_API_KEY'),
            api_secret=os.getenv('FUTURES_API_SECRET'),
            testnet=self.testnet
        )
        
        try:
            data = await loader.get_historical_data(
                symbol=self.symbol,
                interval=self.interval,
                days_back=days
            )
            
            if data is None or len(data) < DATA_CONFIG['min_data_points']:
                logger.error(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è {self.symbol}: {len(data) if data is not None else 0}")
                return None
            
            logger.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è {self.symbol}")
            return data
            
        finally:
            await loader.close()
    
    def prepare_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """–†–æ–∑—à–∏—Ä–µ–Ω–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ—ñ—á–µ–π –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º Rust —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤"""
        logger.info(f"üîß –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Ä–æ–∑—à–∏—Ä–µ–Ω–∏—Ö —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ –¥–ª—è {self.symbol}...")
        
        # –ë–∞–∑–æ–≤—ñ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏ (–∑ optimized_indicators.py - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î Rust —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π)
        df = calculate_all_indicators(data)
        
        # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –±–∞–∑–æ–≤—ñ —Ñ—ñ—á—ñ
        df['returns'] = df['close'].pct_change()
        df['log_returns'] = np.log(df['close'] / df['close'].shift(1))
        df['price_momentum'] = df['close'] - df['close'].shift(5)
        df['volume_momentum'] = df['volume'] - df['volume'].shift(5)
        
        # RUST —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏ (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π) - –Ω–∞–π—à–≤–∏–¥—à—ñ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è
        df = self.feature_engineer.add_rust_indicators(df)
        
        # –î–æ–¥–∞—Ç–∫–æ–≤—ñ —à–≤–∏–¥–∫—ñ —Ñ—ñ—á—ñ (pandas)
        df = self.feature_engineer.add_rolling_stats(df)
        df = self.feature_engineer.add_price_patterns(df)
        df = self.feature_engineer.add_volatility_features(df)
        df = self.feature_engineer.add_momentum_features(df)
        
        # –í–∏–¥–∞–ª—è—î–º–æ NaN
        initial_len = len(df)
        df = df.dropna()
        dropped = initial_len - len(df)
        
        logger.info(f"‚úÖ –ü—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å—ñ–≤ –∑ {len(df.columns)} —Ñ—ñ—á–∞–º–∏ (dropped {dropped} NaN)")
        return df
    
    def create_sequences(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π"""
        sequence_length = self.config['sequence_length']
        
        feature_cols = [col for col in data.columns 
                       if col not in ['timestamp', 'open_time', 'close_time']]
        
        scaled_data = self.scaler.fit_transform(data[feature_cols].values)
        
        X, y = [], []
        
        for i in range(sequence_length, len(scaled_data) - 1):
            X.append(scaled_data[i-sequence_length:i])
            current_price = data.iloc[i]['close']
            next_price = data.iloc[i + 1]['close']
            price_change = (next_price - current_price) / current_price
            y.append(price_change)
        
        X = np.array(X)
        y = np.array(y)
        
        logger.info(f"‚úÖ –°—Ç–≤–æ—Ä–µ–Ω–æ {len(X)} –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π, —Ä–æ–∑–º—ñ—Ä: {X.shape}")
        return X, y
    
    def build_and_compile_model(self, input_shape: Tuple) -> tf.keras.Model:
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ"""
        logger.info(f"ü§ñ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {self.config['model_type']}")
        
        model_builder = OptimizedPricePredictionModel(
            input_shape=input_shape,
            model_type=self.config['model_type'],
            model_config=self.config
        )
        
        model = model_builder.create_model()
        model = model_builder.compile_model(
            model, 
            learning_rate=self.config['learning_rate']
        )
        
        self.model = model
        return model
    
    def train(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è–º–∏"""
        logger.info(f"üöÄ –ü–æ—á–∞—Ç–æ–∫ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è {self.symbol}...")
        
        # Cross-validation
        n_splits = TRAINING_IMPROVEMENTS['validation']['n_splits']
        tscv = TimeSeriesSplit(n_splits=n_splits)
        
        from tensorflow.keras.callbacks import (
            EarlyStopping, 
            ReduceLROnPlateau, 
            ModelCheckpoint
        )
        
        model_dir = f'models/advanced_{self.symbol.replace("USDT", "")}'
        os.makedirs(model_dir, exist_ok=True)
        checkpoint_path = f'{model_dir}/best_model.h5'
        
        callbacks = [
            EarlyStopping(
                monitor='val_loss',
                patience=self.config['early_stopping_patience'],
                restore_best_weights=True,
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=self.config['reduce_lr_patience'],
                min_lr=1e-7,
                verbose=1
            ),
            ModelCheckpoint(
                checkpoint_path,
                monitor='val_loss',
                save_best_only=True,
                verbose=1
            )
        ]
        
        # –ë–µ—Ä–µ–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π fold
        train_idx, val_idx = list(tscv.split(X))[-1]
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]
        
        logger.info(f"üìä Train: {len(X_train)}, Val: {len(X_val)}")
        
        # –ü–æ–±—É–¥–æ–≤–∞ –º–æ–¥–µ–ª—ñ
        input_shape = (X_train.shape[1], X_train.shape[2])
        self.build_and_compile_model(input_shape)
        
        # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=self.config['epochs'],
            batch_size=self.config['batch_size'],
            callbacks=callbacks,
            verbose=1
        )
        
        self.history = history.history
        
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è scaler
        scaler_path = f'{model_dir}/scaler.pkl'
        joblib.dump(self.scaler, scaler_path)
        logger.info(f"‚úÖ Scaler –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {scaler_path}")
        
        val_loss = min(history.history['val_loss'])
        val_dir_acc = max(history.history.get('val_directional_accuracy', [0]))
        
        logger.info(f"‚úÖ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        logger.info(f"   Best val_loss: {val_loss:.6f}")
        logger.info(f"   Best val_directional_accuracy: {val_dir_acc:.4f}")
        
        return {
            'symbol': self.symbol,
            'val_loss': val_loss,
            'val_dir_acc': val_dir_acc,
            'model_path': checkpoint_path,
            'scaler_path': scaler_path
        }


async def train_all_models_advanced():
    """–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è–º–∏"""
    logger.info("=" * 80)
    logger.info("üöÄ –ü–û–ö–†–ê–©–ï–ù–ï –¢–†–ï–ù–£–í–ê–ù–ù–Ø –ú–û–î–ï–õ–ï–ô (Target: 60-70% accuracy)")
    logger.info("=" * 80)
    
    results = []
    
    for symbol in SYMBOLS:
        try:
            logger.info(f"\n{'=' * 80}")
            logger.info(f"üìä –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –ø–æ–∫—Ä–∞—â–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ –¥–ª—è {symbol}")
            logger.info(f"{'=' * 80}\n")
            
            trainer = AdvancedModelTrainer(symbol, INTERVAL)
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
            data = await trainer.load_data()
            if data is None:
                continue
            
            # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ—ñ—á–µ–π
            df = trainer.prepare_features(data)
            
            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π
            X, y = trainer.create_sequences(df)
            
            # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
            result = trainer.train(X, y)
            results.append(result)
            
            logger.info(f"‚úÖ {symbol} —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ! "
                       f"Accuracy: {result['val_dir_acc']:.2%}\n")
            
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è {symbol}: {e}", exc_info=True)
            continue
    
    # –ü—ñ–¥—Å—É–º–æ–∫
    logger.info("\n" + "=" * 80)
    logger.info("üìä –ü–Ü–î–°–£–ú–û–ö –ü–û–ö–†–ê–©–ï–ù–û–ì–û –¢–†–ï–ù–£–í–ê–ù–ù–Ø")
    logger.info("=" * 80)
    
    for result in sorted(results, key=lambda x: x['val_dir_acc'], reverse=True):
        emoji = "üéØ" if result['val_dir_acc'] >= 0.60 else "‚úÖ" if result['val_dir_acc'] >= 0.55 else "‚ö†Ô∏è"
        logger.info(f"{emoji} {result['symbol']:12} | Accuracy: {result['val_dir_acc']:.2%} | "
                   f"Loss: {result['val_loss']:.6f}")
    
    avg_acc = sum(r['val_dir_acc'] for r in results) / len(results)
    logger.info(f"\nüìà –°–µ—Ä–µ–¥–Ω—è accuracy: {avg_acc:.2%}")
    logger.info(f"‚úÖ –ù–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–æ {len(results)}/{len(SYMBOLS)} –º–æ–¥–µ–ª–µ–π")
    logger.info("=" * 80)


if __name__ == "__main__":
    asyncio.run(train_all_models_advanced())
