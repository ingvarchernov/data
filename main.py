# -*- coding: utf-8 -*-
"""
–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π –≥–æ–ª–æ–≤–Ω–∏–π –º–æ–¥—É–ª—å –∑ –Ω–æ–≤–æ—é –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–æ—é
–Ü–Ω—Ç–µ–≥—Ä—É—î –≤—Å—ñ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó: –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ñ—Å—Ç—å, –∫–µ—à—É–≤–∞–Ω–Ω—è, GPU, Rust —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏
"""
import numpy as np
import pandas as pd
import asyncio
import logging
import sys
import os
import argparse
from binance_loader import save_ohlcv_to_db
from datetime import datetime
from pathlib import Path

# –°–∏—Å—Ç–µ–º–Ω—ñ –º–æ–¥—É–ª—ñ
from dotenv import load_dotenv

# –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –º–æ–¥—É–ª—ñ
from optimized_db import db_manager
from optimized_indicators import global_calculator
from optimized_model import OptimizedPricePredictionModel, DatabaseHistoryCallback, DenormalizedMetricsCallback
from cache_system import cache_manager, get_cache_info
from async_architecture import ml_pipeline, init_async_system, shutdown_async_system
from gpu_config import configure_gpu, get_gpu_info
# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ optimized_config –∑–∞–º—ñ—Å—Ç—å config
from optimized_config import SYMBOL, INTERVAL, DAYS_BACK, LOOK_BACK, STEPS, MODEL_CONFIG

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('optimized_app.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class OptimizedCryptoMLSystem:
    """–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç"""
    
    def __init__(self):
        self.initialized = False
        self.gpu_available = False
        
    async def initialize(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏"""
        if self.initialized:
            return
            
        logger.info("üöÄ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ—ó —Å–∏—Å—Ç–µ–º–∏...")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
        load_dotenv()
        self._validate_environment()
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è GPU
        self.gpu_available = configure_gpu()
        if self.gpu_available:
            gpu_info = get_gpu_info()
            logger.info(f"üî• GPU —Å—Ç–∞—Ç—É—Å: {gpu_info}")
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—ó —Å–∏—Å—Ç–µ–º–∏
        await init_async_system()
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–µ—à—É
        logger.info("üíæ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏ –∫–µ—à—É–≤–∞–Ω–Ω—è...")
        cache_stats = get_cache_info()
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–µ—à—É: {cache_stats}")
        
        # –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∑'—î–¥–Ω–∞–Ω–Ω—è –∑ –ë–î
        try:
            await db_manager.execute_query_cached("SELECT 1 as test", use_cache=False)
            logger.info("‚úÖ –ó'—î–¥–Ω–∞–Ω–Ω—è –∑ –±–∞–∑–æ—é –¥–∞–Ω–∏—Ö —É—Å–ø—ñ—à–Ω–µ")
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑'—î–¥–Ω–∞–Ω–Ω—è –∑ –ë–î: {e}")
            raise
        
        self.initialized = True
        logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —É—Å–ø—ñ—à–Ω–æ")
    
    def _validate_environment(self):
        """–í–∞–ª—ñ–¥–∞—Ü—ñ—è –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞"""
        required_vars = ['API_KEY', 'API_SECRET', 'DB_HOST', 'DB_PORT', 'DB_NAME', 'DB_USER', 'DB_PASSWORD']
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            logger.error(f"‚ùå –í—ñ–¥—Å—É—Ç–Ω—ñ –∑–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞: {', '.join(missing_vars)}")
            raise ValueError(f"–ù–µ–æ–±—Ö—ñ–¥–Ω–æ –≤–∏–∑–Ω–∞—á–∏—Ç–∏ –∑–º—ñ–Ω–Ω—ñ: {', '.join(missing_vars)}")
    
    async def process_symbol_optimized(self, 
                                     symbol: str, 
                                     interval: str, 
                                     days_back: int,
                                     look_back: int,
                                     steps: int,
                                     force_retrain: bool = False,
                                     use_cv: bool = False):
        """–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Å–∏–º–≤–æ–ª—É"""
        logger.info(f"üìà –ü–æ—á–∞—Ç–æ–∫ –æ–±—Ä–æ–±–∫–∏ {symbol} ({interval})")
        start_time = datetime.now()
        
        try:
            # –ö–µ—à—É–≤–∞–Ω–Ω—è symbol_id —Ç–∞ interval_id
            cache_key = f"{symbol}_{interval}_ids"
            cached_ids = cache_manager.get(cache_key)
            
            if cached_ids:
                symbol_id, interval_id = cached_ids
            else:
                symbol_id = await db_manager.get_or_create_symbol_id(symbol)
                interval_id = await db_manager.get_or_create_interval_id(interval)
                cache_manager.set(cache_key, (symbol_id, interval_id), ttl=86400)  # 24 –≥–æ–¥–∏–Ω–∏
            
            # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º
            data = await db_manager.get_historical_data_optimized(
                symbol_id, interval_id, days_back, use_cache=True
            )
            
            if data.empty:
                logger.error(f"‚ùå –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è {symbol}")
                return None
            
            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Ç–µ—Ö–Ω—ñ—á–Ω–∏—Ö —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
            indicators = await global_calculator.calculate_all_indicators_batch(data)
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ OHLCV –∫–æ–ª–æ–Ω–∫–∏ –ø–µ—Ä–µ–¥ join
            original_ohlcv = data[['open', 'high', 'low', 'close', 'volume']].copy()
            
            # –î–æ–¥–∞–≤–∞–Ω–Ω—è —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ –¥–æ –¥–∞–Ω–∏—Ö
            for name, indicator in indicators.items():
                if len(indicator) > 0:
                    data = data.join(indicator, how='inner', lsuffix='_orig', rsuffix=f'_{name}')
            
            # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ OHLCV –∫–æ–ª–æ–Ω–∫–∏ (join –º—ñ–≥ —ó—Ö –ø–µ—Ä–µ–ø–∏—Å–∞—Ç–∏)
            for col in ['open', 'high', 'low', 'close', 'volume']:
                if col in original_ohlcv.columns:
                    data[col] = original_ohlcv[col]
            
            # –û—á–∏—â–µ–Ω–Ω—è –≤—ñ–¥ NaN
            data = data.dropna()
            logger.info(f"‚úì –û–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö: {len(data)} –∑–∞–ø–∏—Å—ñ–≤ –ø—ñ—Å–ª—è —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤")
            logger.info(f"üìä –ü—ñ—Å–ª—è –¥–æ–¥–∞–≤–∞–Ω–Ω—è —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤: {len(data)} –∑–∞–ø–∏—Å—ñ–≤")
            
            # –í–ò–î–ê–õ–ï–ù–ù–Ø OUTLIERS - –∫—Ä–∏—Ç–∏—á–Ω–∏–π –∫—Ä–æ–∫ –¥–ª—è —è–∫–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö
            # –í–∏–¥–∞–ª—è—î–º–æ –µ–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è —Ü—ñ–Ω (–±—ñ–ª—å—à–µ 10 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏—Ö –≤—ñ–¥—Ö–∏–ª–µ–Ω—å)
            price_cols = ['close', 'high', 'low', 'open']
            for col in price_cols:
                if col in data.columns:
                    mean_price = data[col].mean()
                    std_price = data[col].std()
                    # –í–∏–¥–∞–ª—è—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è, —è–∫—ñ –≤—ñ–¥—Ö–∏–ª—è—é—Ç—å—Å—è –±—ñ–ª—å—à–µ –Ω—ñ–∂ –Ω–∞ 5 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏—Ö –≤—ñ–¥—Ö–∏–ª–µ–Ω—å
                    data = data[abs(data[col] - mean_price) <= 5 * std_price]
            
            # –í–∏–¥–∞–ª—è—î–º–æ –µ–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ñ –æ–±'—î–º–∏ (–±—ñ–ª—å—à–µ 10 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏—Ö –≤—ñ–¥—Ö–∏–ª–µ–Ω—å)
            if 'volume' in data.columns:
                vol_mean = data['volume'].mean()
                vol_std = data['volume'].std()
                data = data[abs(data['volume'] - vol_mean) <= 10 * vol_std]
            
            # –í–∏–¥–∞–ª—è—î–º–æ –µ–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤
            indicator_cols = ['RSI', 'MACD', 'ATR', 'Stoch_K', 'Stoch_D', 'Williams_R', 'CCI', 'ADX']
            for col in indicator_cols:
                if col in data.columns:
                    # RSI –º–∞—î –±—É—Ç–∏ –º—ñ–∂ 0-100, —ñ–Ω—à—ñ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏ –º–∞—é—Ç—å —Ä–æ–∑—É–º–Ω—ñ –º–µ–∂—ñ
                    if col == 'RSI':
                        data = data[(data[col] >= 0) & (data[col] <= 100)]
                    elif col in ['Stoch_K', 'Stoch_D']:
                        data = data[(data[col] >= -20) & (data[col] <= 120)]  # Stochastic –º–æ–∂–µ –≤–∏—Ö–æ–¥–∏—Ç–∏ –∑–∞ 0-100
                    elif col == 'Williams_R':
                        data = data[(data[col] >= -100) & (data[col] <= 0)]  # Williams %R –≤—ñ–¥ -100 –¥–æ 0
                    else:
                        # –î–ª—è —ñ–Ω—à–∏—Ö —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ –≤–∏–¥–∞–ª—è—î–º–æ –µ–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
                        col_mean = data[col].mean()
                        col_std = data[col].std()
                        data = data[abs(data[col] - col_mean) <= 5 * col_std]
            
            logger.info(f"‚úì –ü—ñ—Å–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è outliers: {len(data)} –∑–∞–ø–∏—Å—ñ–≤")
            
            if len(data) < look_back:
                logger.error(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏: {len(data)} < {look_back}")
                return None
            
            # –î–û–î–ê–¢–ö–û–í–Ü –°–¢–ê–¢–ò–°–¢–ò–ß–ù–Ü –§–Ü–ß–Ü
            # Rolling statistics –¥–ª—è —Ü—ñ–Ω–∏
            data['close_rolling_mean_10'] = data['close'].rolling(10).mean()
            data['close_rolling_std_10'] = data['close'].rolling(10).std()
            data['close_rolling_skew_20'] = data['close'].rolling(20).skew()
            data['close_rolling_kurt_20'] = data['close'].rolling(20).kurt()
            
            # Volume-based features
            if 'volume' in data.columns:
                data['volume_rolling_mean_10'] = data['volume'].rolling(10).mean()
                data['volume_rolling_std_10'] = data['volume'].rolling(10).std()
                data['volume_to_price_ratio'] = data['volume'] / (data['close'] + 1e-6)
                data['volume_change'] = data['volume'].pct_change().fillna(0)
            
            # RSI-based features
            if 'RSI' in data.columns:
                data['rsi_overbought'] = (data['RSI'] > 70).astype(int)
                data['rsi_oversold'] = (data['RSI'] < 30).astype(int)
                data['rsi_divergence'] = data['RSI'].diff(5)  # 5-period RSI change
            
            # MACD-based features
            if 'MACD' in data.columns and 'MACD_Signal' in data.columns:
                data['macd_histogram'] = data['MACD'] - data['MACD_Signal']
                data['macd_crossover'] = np.where(data['MACD'] > data['MACD_Signal'], 1, -1)
                data['macd_trend'] = data['macd_histogram'].rolling(5).mean()
            
            # Bollinger Bands advanced features
            if 'BB_Upper' in data.columns and 'BB_Lower' in data.columns:
                data['bb_squeeze'] = (data['BB_Upper'] - data['BB_Lower']) / data['close']
                data['bb_breakout_up'] = (data['close'] > data['BB_Upper']).astype(int)
                data['bb_breakout_down'] = (data['close'] < data['BB_Lower']).astype(int)
            
            # Stochastic features
            if 'Stoch_K' in data.columns and 'Stoch_D' in data.columns:
                data['stoch_divergence'] = data['Stoch_K'] - data['Stoch_D']
                data['stoch_overbought'] = (data['Stoch_K'] > 80).astype(int)
                data['stoch_oversold'] = (data['Stoch_K'] < 20).astype(int)
            
            # ATR-based volatility features
            if 'ATR' in data.columns:
                data['atr_ratio'] = data['ATR'] / data['close']
                data['atr_change'] = data['ATR'].pct_change().fillna(0)
            
            # Price action patterns
            data['doji'] = abs(data['close'] - data['open']) / (data['high'] - data['low'] + 1e-6) < 0.1
            data['hammer'] = ((data['high'] - data['low'] > 0) & 
                            (abs(data['open'] - data['close']) < 0.3 * (data['high'] - data['low'])) & 
                            ((data['low'] - data['close']) > 0.6 * (data['high'] - data['low']))).astype(int)
            
            # Time-based features (—è–∫—â–æ —î timestamp)
            if 'timestamp' in data.columns:
                data['hour'] = pd.to_datetime(data['timestamp']).dt.hour
                data['day_of_week'] = pd.to_datetime(data['timestamp']).dt.dayofweek
                data['month'] = pd.to_datetime(data['timestamp']).dt.month
                # –¶–∏–∫–ª—ñ—á–Ω—ñ features –¥–ª—è —á–∞—Å—É
                data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)
                data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)
                data['dow_sin'] = np.sin(2 * np.pi * data['day_of_week'] / 7)
                data['dow_cos'] = np.cos(2 * np.pi * data['day_of_week'] / 7)
            
            # –†–æ–∑—à–∏—Ä–µ–Ω–∏–π —Å–ø–∏—Å–æ–∫ —Ñ—ñ—á–µ–π –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è
            strategic_features = [
                # Basic OHLCV
                'close', 'volume', 'high', 'low', 'open',
                
                # Technical indicators
                'RSI', 'MACD', 'MACD_Signal', 'ATR', 'EMA_20', 'EMA_10', 'EMA_50',
                'Stoch_K', 'Stoch_D', 'Williams_R', 'CCI',
                
                # Price-based features
                'trend', 'volatility', 'return', 'momentum', 'momentum_10', 'momentum_20',
                'return_5', 'return_10', 'close_lag1', 'close_lag2', 'close_diff', 'log_return',
                'close_rolling_mean_10', 'close_rolling_std_10', 'close_rolling_skew_20', 'close_rolling_kurt_20',
                
                # Volume features
                'volume_pct', 'volume_ma5', 'volume_ma20', 'volume_std',
                'volume_rolling_mean_10', 'volume_rolling_std_10', 'volume_to_price_ratio', 'volume_change',
                
                # Bollinger Bands
                'bb_dist_upper', 'bb_dist_lower', 'bb_width', 'bb_position', 'bb_squeeze', 'bb_breakout_up', 'bb_breakout_down',
                
                # RSI features
                'rsi_overbought', 'rsi_oversold', 'rsi_divergence',
                
                # MACD features
                'macd_histogram', 'macd_crossover', 'macd_trend',
                
                # Stochastic features
                'stoch_divergence', 'stoch_overbought', 'stoch_oversold',
                
                # ATR features
                'atr_ratio', 'atr_change',
                
                # Price action patterns
                'doji', 'hammer', 'high_low_ratio', 'close_open_ratio',
                
                # Time features (if available)
                'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos'
            ]
            feature_columns = [f for f in strategic_features if f in data.columns]
            
            # –í–∏–¥–∞–ª—è—î–º–æ NaN –ø—ñ—Å–ª—è lag-—Ñ—ñ—á–µ–π —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞ Inf
            data = data.replace([np.inf, -np.inf], np.nan)
            data = data.dropna()
            
            if len(data) < look_back:
                logger.error(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏: {len(data)} < {look_back}")
                return None
            
            logger.info(f"‚úì –§—ñ–Ω–∞–ª—å–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç: {len(data)} –∑–∞–ø–∏—Å—ñ–≤, {len(feature_columns)} —Ñ—ñ—á–µ–π")
            
            # Time-series validation: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –°–ï–†–ï–î–ù–Ü 20% —è–∫ –≤–∞–ª—ñ–¥–∞—Ü—ñ—é (–Ω–µ –æ—Å—Ç–∞–Ω–Ω—ñ!)
            # –î–ª—è —Ñ—ñ–Ω–∞–Ω—Å–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö –∫—Ä–∞—â–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ –∑ —Å–µ—Ä–µ–¥–∏–Ω–∏ –ø–µ—Ä—ñ–æ–¥—É
            # —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –ø—Ä–æ–±–ª–µ–º –∑ —Ä—ñ–∑–Ω–∏–º–∏ —Ä–∏–Ω–∫–æ–≤–∏–º–∏ —É–º–æ–≤–∞–º–∏

            # –†–æ–∑–¥—ñ–ª—è—î–º–æ –Ω–∞ train/val/test: 60% / 20% / 20%
            n_total = len(data)
            train_end = int(n_total * 0.6)
            val_end = int(n_total * 0.8)

            train_data = data.iloc[:train_end]
            val_data = data.iloc[train_end:val_end]
            # test_data = data.iloc[val_end:]  # –∑–∞—Ä–µ–∑–µ—Ä–≤–æ–≤–∞–Ω–æ –¥–ª—è —Ñ—ñ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è

            logger.info(f"üìä –•—Ä–æ–Ω–æ–ª–æ–≥—ñ—á–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª: Train={len(train_data)}, Val={len(val_data)} (60%/20%)")
            
            X_train_raw = train_data[feature_columns].values
            X_val_raw = val_data[feature_columns].values

            # –í–ê–ñ–õ–ò–í–û: RobustScaler –∫—Ä–∞—â–µ –¥–ª—è trending —Ñ—ñ–Ω–∞–Ω—Å–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –º–µ–¥—ñ–∞–Ω—É —Ç–∞ IQR –∑–∞–º—ñ—Å—Ç—å min/max, —Å—Ç—ñ–π–∫–∏–π –¥–æ outliers
            from sklearn.preprocessing import RobustScaler
            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train_raw)
            X_val_scaled = scaler.transform(X_val_raw)  # transform, –ù–ï fit_transform!
            
            # RobustScaler –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î center_ —Ç–∞ scale_ –∑–∞–º—ñ—Å—Ç—å min/max
            close_idx_feat = feature_columns.index('close')
            logger.info(f"‚úì Scaler: train close center={scaler.center_[close_idx_feat]:.2f}, scale={scaler.scale_[close_idx_feat]:.2f}")

            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π –¥–ª—è train
            X_train_sequences = []
            for i in range(len(X_train_scaled) - look_back):
                X_train_sequences.append(X_train_scaled[i:i + look_back])
            X_train_sequences = np.array(X_train_sequences)
            
            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π –¥–ª—è val
            X_val_sequences = []
            for i in range(len(X_val_scaled) - look_back):
                X_val_sequences.append(X_val_scaled[i:i + look_back])
            X_val_sequences = np.array(X_val_sequences)
            
            # –¶—ñ–ª—å–æ–≤—ñ –∑–º—ñ–Ω–Ω—ñ - –∞–±—Å–æ–ª—é—Ç–Ω—ñ —Ü—ñ–Ω–∏ (close), –∞ –Ω–µ —Ä—ñ–∑–Ω–∏—Ü—ñ
            close_idx = feature_columns.index('close')
            y_train = X_train_scaled[look_back:, close_idx]  # –Ω–∞—Å—Ç—É–ø–Ω—ñ –∞–±—Å–æ–ª—é—Ç–Ω—ñ —Ü—ñ–Ω–∏
            y_val = X_val_scaled[look_back:, close_idx]

            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —Å–ø—ñ–≤–ø–∞–¥–∞—é—Ç—å —Ä–æ–∑–º—ñ—Ä–∏
            expected_train_len = len(X_train_scaled) - look_back
            expected_val_len = len(X_val_scaled) - look_back

            if len(y_train) != expected_train_len or len(y_val) != expected_val_len:
                logger.error(f"‚ùå –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å y –Ω–µ —Å–ø—ñ–≤–ø–∞–¥–∞—î: y_train={len(y_train)}, expected={expected_train_len}")
                return None
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —Å–ø—ñ–≤–ø–∞–¥–∞—é—Ç—å —Ä–æ–∑–º—ñ—Ä–∏
            expected_train_len = len(X_train_scaled) - look_back
            expected_val_len = len(X_val_scaled) - look_back
            
            if len(y_train) != expected_train_len or len(y_val) != expected_val_len:
                logger.error(f"‚ùå –†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å y –Ω–µ —Å–ø—ñ–≤–ø–∞–¥–∞—î: y_train={len(y_train)}, expected={expected_train_len}")
                return None
            
            X_sequences = X_train_sequences  # –î–ª—è —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ –∑ –Ω–∞—Å—Ç—É–ø–Ω–∏–º –∫–æ–¥–æ–º
            
            # –î–ª—è prediction –ø–æ—Ç—Ä—ñ–±–Ω—ñ –≤—Å—ñ –¥–∞–Ω—ñ —Ä–∞–∑–æ–º
            X_data = data[feature_columns].values
            X_all_scaled = scaler.transform(X_data)  # transform –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ train scaler

            if len(X_sequences) == 0:
                logger.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ")
                return None
            
            # 4. –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è/–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ

            model_path = f"models/optimized_{symbol}_{interval}.keras"

            retrain = force_retrain or not Path(model_path).exists()
            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ input_shape —É –º–µ—Ç–∞–¥–∞–Ω–∏—Ö
            metadata_path = model_path.replace('.keras', '_metadata.json')
            if not retrain and Path(metadata_path).exists():
                import json
                with open(metadata_path, 'r') as f:
                    meta = json.load(f)
                old_shape = tuple(meta.get('data_shape', [0, 0]))
                new_shape = X_sequences.shape
                if old_shape != new_shape:
                    logger.info("‚ö†Ô∏è Input shape –∑–º—ñ–Ω–∏–≤—Å—è, –ø–µ—Ä–µ—Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ...")
                    retrain = True

            if retrain:
                logger.info("ü§ñ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –Ω–æ–≤–æ—ó –º–æ–¥–µ–ª—ñ...")
                close_index = feature_columns.index('close')
                
                model_builder = OptimizedPricePredictionModel(
                    input_shape=(look_back, len(feature_columns)),
                    model_type="advanced_lstm",
                    scaler=scaler,
                    feature_index=close_index
                )
                
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≤–∂–µ –ø—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ñ X_train_sequences, X_val_sequences, y_train, y_val
                X_train = X_train_sequences.astype(np.float32)
                X_val = X_val_sequences.astype(np.float32)
                y_train = y_train.astype(np.float32)
                y_val = y_val.astype(np.float32)
                
                # –õ–æ–≥—É–≤–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó
                logger.info(f"y_train: min={y_train.min():.4f}, max={y_train.max():.4f}, mean={y_train.mean():.4f}, std={y_train.std():.4f}")
                logger.info(f"y_val: min={y_val.min():.4f}, max={y_val.max():.4f}, mean={y_val.mean():.4f}, std={y_val.std():.4f}")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ NaN/Inf
                if np.isnan(y_train).any() or np.isnan(y_val).any():
                    logger.error("‚ùå y_train –∞–±–æ y_val –º—ñ—Å—Ç–∏—Ç—å NaN!")
                    return None
                if np.isinf(y_train).any() or np.isinf(y_val).any():
                    logger.error("‚ùå y_train –∞–±–æ y_val –º—ñ—Å—Ç–∏—Ç—å Inf!")
                    return None
                
                # –°—Ç–≤–æ—Ä—é—î–º–æ callback –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –ë–î
                db_callback = DatabaseHistoryCallback(
                    db_engine=db_manager.sync_engine,
                    symbol_id=symbol_id,
                    interval_id=interval_id,
                    fold=1
                )
                
                # –°—Ç–≤–æ—Ä—é—î–º–æ callback –¥–ª—è –≤–∏–≤–æ–¥—É –¥–µ–Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫
                denorm_callback = DenormalizedMetricsCallback(
                    scaler=scaler,
                    feature_index=feature_columns.index('close'),
                    X_val=X_val,
                    y_val=y_val
                )
                
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑ optimized_config
                model, history = model_builder.train_model(
                    X_train, y_train, X_val, y_val,
                    model_save_path=model_path,
                    epochs=MODEL_CONFIG['epochs'],
                    batch_size=MODEL_CONFIG['batch_size'],
                    learning_rate=MODEL_CONFIG['learning_rate'],
                    db_callback=db_callback,
                    additional_callbacks=[denorm_callback]
                )
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–µ—Ç–∞–¥–∞–Ω—ñ –∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ scaler
                scaler_params = {}
                if hasattr(scaler, 'data_min_'):
                    # MinMaxScaler
                    scaler_params = {
                        'type': 'MinMaxScaler',
                        'min': scaler.data_min_.tolist(),
                        'max': scaler.data_max_.tolist()
                    }
                elif hasattr(scaler, 'center_'):
                    # RobustScaler –∞–±–æ StandardScaler
                    scaler_type = type(scaler).__name__
                    scaler_params = {
                        'type': scaler_type,
                        'center': scaler.center_.tolist(),
                        'scale': scaler.scale_.tolist()
                    }
                
                metadata = {
                    'symbol': symbol,
                    'interval': interval,
                    'features': feature_columns,
                    'scaler_params': scaler_params,
                    'trained_at': datetime.now().isoformat(),
                    'data_shape': X_sequences.shape,
                    'model_type': 'advanced_lstm'
                }
                model_builder.save_model_with_metadata(model, model_path, metadata)
            else:
                logger.info("üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å–Ω—É—é—á–æ—ó –º–æ–¥–µ–ª—ñ...")
                model_builder = OptimizedPricePredictionModel(
                    input_shape=(look_back, len(feature_columns)),
                    model_type="advanced_lstm",
                    scaler=scaler,
                    feature_index=feature_columns.index('close')
                )
                model = model_builder.load_model_with_custom_objects(model_path)
                
                # –Ø–∫—â–æ –º–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –±–µ–∑ –∫–æ–º–ø—ñ–ª—è—Ü—ñ—ó, –ø–µ—Ä–µ–∫–æ–º–ø—ñ–ª—é—î–º–æ —ó—ó
                if not model.compiled:
                    logger.info("üîß –ú–æ–¥–µ–ª—å –Ω–µ —Å–∫–æ–º–ø—ñ–ª—å–æ–≤–∞–Ω–∞, –∫–æ–º–ø—ñ–ª—é—î–º–æ...")
                    model = model_builder.recompile_loaded_model(model)
            
            # 5. –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
            logger.info("üîÆ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤...")
            
            # –ë–µ—Ä–µ–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
            last_sequence = X_all_scaled[-look_back:].reshape(1, look_back, len(feature_columns))
            
            predictions = []
            current_sequence = last_sequence.copy()

            for step in range(steps):
                # –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥–±–∞—á–∞—î –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—É –∞–±—Å–æ–ª—é—Ç–Ω—É —Ü—ñ–Ω—É
                pred_scaled = model.predict(current_sequence, verbose=0)[0, 0]

                # –î–µ–Ω–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—É —Ü—ñ–Ω—É
                dummy = np.zeros((1, len(feature_columns)))
                dummy[0, close_idx] = pred_scaled
                predicted_price = scaler.inverse_transform(dummy)[0, close_idx]

                predictions.append(float(predicted_price))

                # –û–Ω–æ–≤–ª—é—î–º–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å –¥–ª—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑—É
                new_row = current_sequence[0, -1, :].copy()
                new_row[close_idx] = pred_scaled  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—É –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—É —Ü—ñ–Ω—É
                current_sequence = np.roll(current_sequence, -1, axis=1)
                current_sequence[0, -1, :] = new_row
            
            # –î–µ–Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤ - –ø—Ä–æ—Å—Ç–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≤–∂–µ –¥–µ–Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ —Ü—ñ–Ω–∏
            predictions_denorm = predictions
            
            # 6. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            # –î–µ–Ω–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –æ—Å—Ç–∞–Ω–Ω—é —Ü—ñ–Ω—É (inverse scaler)
            last_scaled = scaler.inverse_transform([X_all_scaled[-1]])[0]
            last_price_denorm = last_scaled[feature_columns.index('close')]
            
            results = {
                'symbol': symbol,
                'interval': interval,
                'timestamp': datetime.now().isoformat(),
                'last_price': last_price_denorm,
                'predictions': predictions_denorm,
                'steps': steps,
                'processing_time': (datetime.now() - start_time).total_seconds()
            }
            
            # –ö–µ—à—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            cache_key = f"predictions:{symbol}:{interval}:{steps}"
            cache_manager.set(cache_key, results, ttl=1800)
            
            logger.info(f"‚úÖ –û–±—Ä–æ–±–∫—É –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {results['processing_time']:.2f}s")
            logger.info(f"üìà –û—Å—Ç–∞–Ω–Ω—è —Ü—ñ–Ω–∞: {results['last_price']:.2f}")
            logger.info(f"üîÆ –ü—Ä–æ–≥–Ω–æ–∑–∏: {[f'{p:.2f}' for p in predictions_denorm]}")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ {symbol}: {e}", exc_info=True)
            return None
    
    async def batch_process_symbols(self, symbols: list, **kwargs):
        """–ü–∞–∫–µ—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Å–∏–º–≤–æ–ª—ñ–≤"""
        logger.info(f"üîÑ –ü–∞–∫–µ—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ {len(symbols)} —Å–∏–º–≤–æ–ª—ñ–≤")
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–¥–∞—á—ñ –¥–ª—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ–≥–æ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
        tasks = []
        for symbol in symbols:
            task = self.process_symbol_optimized(symbol, **kwargs)
            tasks.append(task)
        
        # –í–∏–∫–æ–Ω—É—î–º–æ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ –∑ –æ–±–º–µ–∂–µ–Ω–Ω—è–º
        semaphore = asyncio.Semaphore(3)  # –ú–∞–∫—Å–∏–º—É–º 3 —Å–∏–º–≤–æ–ª–∏ –æ–¥–Ω–æ—á–∞—Å–Ω–æ
        
        async def limited_process(task):
            async with semaphore:
                return await task
        
        limited_tasks = [limited_process(task) for task in tasks]
        results = await asyncio.gather(*limited_tasks, return_exceptions=True)
        
        # –û–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        successful = sum(1 for r in results if r is not None and not isinstance(r, Exception))
        failed = len(results) - successful
        
        logger.info(f"‚úÖ –ü–∞–∫–µ—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {successful} —É—Å–ø—ñ—à–Ω–æ, {failed} –∑ –ø–æ–º–∏–ª–∫–∞–º–∏")
        
        return results
    
    async def get_system_status(self):
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç—É—Å—É —Å–∏—Å—Ç–µ–º–∏"""
        return {
            'initialized': self.initialized,
            'gpu_available': self.gpu_available,
            'gpu_info': get_gpu_info() if self.gpu_available else None,
            'cache_stats': get_cache_info(),
            'worker_stats': ml_pipeline.worker_pool.get_stats() if ml_pipeline.worker_pool else None,
            'timestamp': datetime.now().isoformat()
        }
    
    async def cleanup(self):
        """–û—á–∏—â–µ–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤"""
        logger.info("üßπ –û—á–∏—â–µ–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤...")
        await shutdown_async_system()
        logger.info("‚úÖ –û—á–∏—â–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

# –ì–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä —Å–∏—Å—Ç–µ–º–∏
crypto_system = OptimizedCryptoMLSystem()

async def main():
    """–ì–æ–ª–æ–≤–Ω–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    parser = argparse.ArgumentParser(description="–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç")
    parser.add_argument("--symbol", type=str, default=SYMBOL, help="–¢–æ—Ä–≥–æ–≤–∞ –ø–∞—Ä–∞")
    parser.add_argument("--interval", type=str, default=INTERVAL, help="–Ü–Ω—Ç–µ—Ä–≤–∞–ª —á–∞—Å—É")
    parser.add_argument("--days_back", type=int, default=DAYS_BACK, help="–î–Ω—ñ–≤ —ñ—Å—Ç–æ—Ä—ñ—ó")
    parser.add_argument("--look_back", type=int, default=LOOK_BACK, help="–†–æ–∑–º—ñ—Ä –≤—ñ–∫–Ω–∞ –∑ optimized_config")
    parser.add_argument("--steps", type=int, default=STEPS, help="–ö—Ä–æ–∫—ñ–≤ –ø—Ä–æ–≥–Ω–æ–∑—É")
    parser.add_argument("--force_retrain", action="store_true", help="–ü—Ä–∏–º—É—Å–æ–≤–µ –ø–µ—Ä–µ—Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è")
    parser.add_argument("--use_cv", action="store_true", help="–í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ TimeSeriesSplit cross-validation")
    parser.add_argument("--batch", nargs="+", help="–ü–∞–∫–µ—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Å–∏–º–≤–æ–ª—ñ–≤")
    parser.add_argument("--status", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç–∏ —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º–∏")
    
    args = parser.parse_args()
    
    try:
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏
        await crypto_system.initialize()

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∑ Binance
        logger.info("‚è≥ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∑ Binance...")
        await save_ohlcv_to_db(db_manager, args.symbol, args.interval, days_back=args.days_back)
        logger.info("‚úÖ –î–∞–Ω—ñ –∑ Binance –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —É historical_data")

        if args.status:
            # –ü–æ–∫–∞–∑–∞—Ç–∏ —Å—Ç–∞—Ç—É—Å
            status = await crypto_system.get_system_status()
            logger.info(f"üìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º–∏: {status}")
            return
        
        if args.batch:
            # –ü–∞–∫–µ—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞
            results = await crypto_system.batch_process_symbols(
                symbols=args.batch,
                interval=args.interval,
                days_back=args.days_back,
                look_back=args.look_back,
                steps=args.steps,
                force_retrain=args.force_retrain,
                use_cv=args.use_cv
            )
            
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ {args.batch[i]}: {result}")
                elif result:
                    logger.info(f"‚úÖ {args.batch[i]}: {result['predictions']}")
        else:
            # –û–±—Ä–æ–±–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª—É
            result = await crypto_system.process_symbol_optimized(
                symbol=args.symbol,
                interval=args.interval,
                days_back=args.days_back,
                look_back=args.look_back,
                steps=args.steps,
                force_retrain=args.force_retrain,
                use_cv=args.use_cv
            )
            
            if result:
                logger.info("üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è:")
                logger.info(f"   –°–∏–º–≤–æ–ª: {result['symbol']}")
                logger.info(f"   –û—Å—Ç–∞–Ω–Ω—è —Ü—ñ–Ω–∞: {result['last_price']:.2f}")
                logger.info(f"   –ü—Ä–æ–≥–Ω–æ–∑–∏: {[f'{p:.2f}' for p in result['predictions']]}")
                logger.info(f"   –ß–∞—Å –æ–±—Ä–æ–±–∫–∏: {result['processing_time']:.2f}s")
    
    except KeyboardInterrupt:
        logger.info("‚è∏Ô∏è –û—Ç—Ä–∏–º–∞–Ω–æ —Å–∏–≥–Ω–∞–ª –ø–µ—Ä–µ—Ä–∏–≤–∞–Ω–Ω—è")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}", exc_info=True)
    finally:
        await crypto_system.cleanup()

if __name__ == "__main__":
    # –Ü–º–ø–æ—Ä—Ç numpy –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤ —Ñ—É–Ω–∫—Ü—ñ—ó
    import numpy as np
    from sklearn.preprocessing import StandardScaler
    
    # –ó–∞–ø—É—Å–∫ –≥–æ–ª–æ–≤–Ω–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó
    asyncio.run(main())