# -*- coding: utf-8 -*-
"""
–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π –≥–æ–ª–æ–≤–Ω–∏–π –º–æ–¥—É–ª—å –∑ –Ω–æ–≤–æ—é –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–æ—é
–Ü–Ω—Ç–µ–≥—Ä—É—î –≤—Å—ñ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó: –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ñ—Å—Ç—å, –∫–µ—à—É–≤–∞–Ω–Ω—è, GPU, Rust —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏
"""
import asyncio
import logging
import sys
import os
import argparse
from binance_loader import save_ohlcv_to_db
from datetime import datetime
from pathlib import Path

# –°–∏—Å—Ç–µ–º–Ω—ñ –º–æ–¥—É–ª—ñ
from dotenv import load_dotenv

# –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –º–æ–¥—É–ª—ñ
from optimized_db import db_manager
from optimized_indicators import global_calculator
from optimized_model import OptimizedPricePredictionModel
from cache_system import cache_manager, get_cache_info
from async_architecture import ml_pipeline, init_async_system, shutdown_async_system
from gpu_config import configure_gpu, get_gpu_info
from config import SYMBOL, INTERVAL, DAYS_BACK, LOOK_BACK, STEPS

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('optimized_app.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class OptimizedCryptoMLSystem:
    """–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç"""
    
    def __init__(self):
        self.initialized = False
        self.gpu_available = False
        
    async def initialize(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏"""
        if self.initialized:
            return
            
        logger.info("üöÄ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ—ó —Å–∏—Å—Ç–µ–º–∏...")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
        load_dotenv()
        self._validate_environment()
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è GPU
        self.gpu_available = configure_gpu()
        if self.gpu_available:
            gpu_info = get_gpu_info()
            logger.info(f"üî• GPU —Å—Ç–∞—Ç—É—Å: {gpu_info}")
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—ó —Å–∏—Å—Ç–µ–º–∏
        await init_async_system()
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–µ—à—É
        logger.info("üíæ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏ –∫–µ—à—É–≤–∞–Ω–Ω—è...")
        cache_stats = get_cache_info()
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–µ—à—É: {cache_stats}")
        
        # –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∑'—î–¥–Ω–∞–Ω–Ω—è –∑ –ë–î
        try:
            await db_manager.execute_query_cached("SELECT 1 as test", use_cache=False)
            logger.info("‚úÖ –ó'—î–¥–Ω–∞–Ω–Ω—è –∑ –±–∞–∑–æ—é –¥–∞–Ω–∏—Ö —É—Å–ø—ñ—à–Ω–µ")
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑'—î–¥–Ω–∞–Ω–Ω—è –∑ –ë–î: {e}")
            raise
        
        self.initialized = True
        logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —É—Å–ø—ñ—à–Ω–æ")
    
    def _validate_environment(self):
        """–í–∞–ª—ñ–¥–∞—Ü—ñ—è –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞"""
        required_vars = ['API_KEY', 'API_SECRET', 'DB_HOST', 'DB_PORT', 'DB_NAME', 'DB_USER', 'DB_PASSWORD']
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            logger.error(f"‚ùå –í—ñ–¥—Å—É—Ç–Ω—ñ –∑–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞: {', '.join(missing_vars)}")
            raise ValueError(f"–ù–µ–æ–±—Ö—ñ–¥–Ω–æ –≤–∏–∑–Ω–∞—á–∏—Ç–∏ –∑–º—ñ–Ω–Ω—ñ: {', '.join(missing_vars)}")
    
    async def process_symbol_optimized(self, 
                                     symbol: str, 
                                     interval: str, 
                                     days_back: int,
                                     look_back: int,
                                     steps: int,
                                     force_retrain: bool = False):
        """–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Å–∏–º–≤–æ–ª—É"""
        logger.info(f"üìà –ü–æ—á–∞—Ç–æ–∫ –æ–±—Ä–æ–±–∫–∏ {symbol} ({interval})")
        start_time = datetime.now()
        
        try:
            # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö
            logger.info("üìä –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö...")
            symbol_id = await db_manager.get_or_create_symbol_id(symbol)
            interval_id = await db_manager.get_or_create_interval_id(interval)
            
            # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º
            data = await db_manager.get_historical_data_optimized(
                symbol_id, interval_id, days_back, use_cache=True
            )
            
            if data.empty:
                logger.error(f"‚ùå –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è {symbol}")
                return None
            
            logger.info(f"üìä –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å—ñ–≤")
            
            # 2. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Ç–µ—Ö–Ω—ñ—á–Ω–∏—Ö —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
            logger.info("üîß –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Ç–µ—Ö–Ω—ñ—á–Ω–∏—Ö —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤...")
            indicators = await global_calculator.calculate_all_indicators_batch(data)
            
            # –î–æ–¥–∞–≤–∞–Ω–Ω—è —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ –¥–æ –¥–∞–Ω–∏—Ö
            for name, indicator in indicators.items():
                if len(indicator) > 0:
                    # –í–∏—Ä—ñ–≤–Ω—é—î–º–æ —ñ–Ω–¥–µ–∫—Å–∏, —É–Ω–∏–∫–∞—î–º–æ –¥—É–±–ª—é–≤–∞–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫
                    data = data.join(indicator, how='inner', lsuffix='_orig', rsuffix=f'_{name}')
            
            # –û—á–∏—â–µ–Ω–Ω—è –≤—ñ–¥ NaN
            data = data.dropna()
            logger.info(f"üìä –ü—ñ—Å–ª—è –¥–æ–¥–∞–≤–∞–Ω–Ω—è —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤: {len(data)} –∑–∞–ø–∏—Å—ñ–≤")
            
            if len(data) < look_back:
                logger.error(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏: {len(data)} < {look_back}")
                return None
            
            # 3. –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—á–Ω–∏—Ö —Ñ—ñ—á–µ–π –¥–ª—è ML
            # –î–æ–¥–∞—î–º–æ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—á–Ω—ñ —Ñ—ñ—á—ñ
            data['trend'] = data['close'] - data['EMA_20'] if 'EMA_20' in data.columns else 0
            data['volatility'] = data['ATR'] if 'ATR' in data.columns else 0
            data['return'] = data['close'].pct_change().fillna(0)
            data['momentum'] = data['close'] - data['close'].shift(5).fillna(0)
            if 'BB_Upper' in data.columns and 'BB_Lower' in data.columns:
                data['bb_dist_upper'] = data['BB_Upper'] - data['close']
                data['bb_dist_lower'] = data['close'] - data['BB_Lower']
            # –î–æ–¥–∞—î–º–æ –≤—Å—ñ —Ç–µ—Ö–Ω—ñ—á–Ω—ñ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏
            strategic_features = ['trend', 'volatility', 'return', 'momentum', 'bb_dist_upper', 'bb_dist_lower',
                                  'RSI', 'MACD', 'MACD_Signal', 'Stoch_K', 'Stoch_D', 'ATR', 'EMA_20', 'BB_Upper', 'BB_Lower']
            # –î–æ–¥–∞—î–º–æ –æ–±'—î–º
            if 'volume' in data.columns:
                strategic_features.append('volume')
            # –§–æ—Ä–º—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π —Å–ø–∏—Å–æ–∫ —Ñ—ñ—á–µ–π
            feature_columns = [col for col in data.columns if col not in ['timestamp', 'data_id']]
            # –î–æ–¥–∞—î–º–æ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—á–Ω—ñ —Ñ—ñ—á—ñ, —è–∫—â–æ —ó—Ö –Ω–µ–º–∞—î
            for f in strategic_features:
                if f in data.columns and f not in feature_columns:
                    feature_columns.append(f)
            X_data = data[feature_columns].values

            # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
            from sklearn.preprocessing import StandardScaler
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X_data)

            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π
            X_sequences = []
            for i in range(len(X_scaled) - look_back):
                X_sequences.append(X_scaled[i:i + look_back])
            X_sequences = np.array(X_sequences)

            if len(X_sequences) == 0:
                logger.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ")
                return None
            
            # 4. –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è/–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
            model_path = f"models/optimized_{symbol}_{interval}.keras"
            
            if force_retrain or not Path(model_path).exists():
                logger.info("ü§ñ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –Ω–æ–≤–æ—ó –º–æ–¥–µ–ª—ñ...")
                
                # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
                model_builder = OptimizedPricePredictionModel(
                    input_shape=(look_back, len(feature_columns)),
                    model_type="transformer_lstm"
                )
                
                # –ü–æ–¥—ñ–ª –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—É —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω—É –≤–∏–±—ñ—Ä–∫–∏
                split_idx = int(len(X_sequences) * 0.8)
                X_train = X_sequences[:split_idx]
                X_val = X_sequences[split_idx:]
                
                # –¶—ñ–ª—å–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è (–ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞—Å—Ç—É–ø–Ω–æ—ó —Ü—ñ–Ω–∏)
                y_train = X_scaled[look_back:split_idx + look_back, feature_columns.index('close')]
                y_val = X_scaled[split_idx + look_back:, feature_columns.index('close')]
                
                # –Ø–≤–Ω–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—è —Ç–∏–ø—ñ–≤ –¥–ª—è CuDNN
                X_train = X_train.astype(np.float32)
                X_val = X_val.astype(np.float32)
                y_train = y_train.astype(np.float32)
                y_val = y_val.astype(np.float32)
                # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
                model, history = model_builder.train_model(
                    X_train, y_train, X_val, y_val,
                    model_save_path=model_path,
                    epochs=100,
                    batch_size=64, 
                    learning_rate=0.001
                )
                
                # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–µ—Ç–∞–¥–∞–Ω–∏—Ö
                metadata = {
                    'symbol': symbol,
                    'interval': interval,
                    'features': feature_columns,
                    'scaler_params': {
                        'mean': scaler.mean_.tolist(),
                        'scale': scaler.scale_.tolist()
                    },
                    'trained_at': datetime.now().isoformat(),
                    'data_shape': X_sequences.shape,
                    'model_type': 'transformer_lstm'
                }
                
                model_builder.save_model_with_metadata(model, model_path, metadata)
                
            else:
                logger.info("üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å–Ω—É—é—á–æ—ó –º–æ–¥–µ–ª—ñ...")
                model_builder = OptimizedPricePredictionModel(
                    input_shape=(look_back, len(feature_columns)),
                    model_type="transformer_lstm"
                )
                model = model_builder.load_model_with_custom_objects(model_path)
            
            # 5. –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
            logger.info("üîÆ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤...")
            
            # –ë–µ—Ä–µ–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
            last_sequence = X_scaled[-look_back:].reshape(1, look_back, len(feature_columns))
            
            predictions = []
            current_sequence = last_sequence.copy()
            
            for step in range(steps):
                pred = model.predict(current_sequence, verbose=0)
                predictions.append(float(pred[0, 0].item()))
                # –û–Ω–æ–≤–ª—é—î–º–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å –¥–ª—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑—É
                new_row = current_sequence[0, -1, :].copy()
                new_row[feature_columns.index('close')] = float(pred[0, 0].item())
                # –ó—Å—É–≤–∞—î–º–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å
                current_sequence = np.roll(current_sequence, -1, axis=1)
                current_sequence[0, -1, :] = new_row
            
            # –î–µ–Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤
            # –î–µ–Ω–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –∫–æ–∂–µ–Ω –ø—Ä–æ–≥–Ω–æ–∑ –æ–∫—Ä–µ–º–æ, –ø—ñ–¥—Å—Ç–∞–≤–ª—è—é—á–∏ –π–æ–≥–æ —É –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π –≤–µ–∫—Ç–æ—Ä —Ñ—ñ—á–µ–π
            last_row = X_data[-1]
            predictions_denorm = []
            for p in predictions:
                denorm_vec = last_row.copy()
                denorm_vec[feature_columns.index('close')] = p
                denorm = scaler.inverse_transform([denorm_vec])[0][feature_columns.index('close')]
                predictions_denorm.append(denorm)
            
            # 6. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            results = {
                'symbol': symbol,
                'interval': interval,
                'timestamp': datetime.now().isoformat(),
                # –î–µ–Ω–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –æ—Å—Ç–∞–Ω–Ω—é —Ü—ñ–Ω—É —á–µ—Ä–µ–∑ scaler
                'last_price': scaler.inverse_transform([X_data[-1]])[0][feature_columns.index('close')],
                'predictions': predictions_denorm.tolist(),
                'steps': steps,
                'processing_time': (datetime.now() - start_time).total_seconds()
            }
            
            # –ö–µ—à—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            cache_key = f"predictions:{symbol}:{interval}:{steps}"
            cache_manager.set(cache_key, results, ttl=1800)
            
            logger.info(f"‚úÖ –û–±—Ä–æ–±–∫—É –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {results['processing_time']:.2f}s")
            logger.info(f"üìà –û—Å—Ç–∞–Ω–Ω—è —Ü—ñ–Ω–∞: {results['last_price']:.2f}")
            logger.info(f"üîÆ –ü—Ä–æ–≥–Ω–æ–∑–∏: {[f'{p:.2f}' for p in predictions_denorm]}")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ {symbol}: {e}", exc_info=True)
            return None
    
    async def batch_process_symbols(self, symbols: list, **kwargs):
        """–ü–∞–∫–µ—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Å–∏–º–≤–æ–ª—ñ–≤"""
        logger.info(f"üîÑ –ü–∞–∫–µ—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ {len(symbols)} —Å–∏–º–≤–æ–ª—ñ–≤")
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–¥–∞—á—ñ –¥–ª—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ–≥–æ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
        tasks = []
        for symbol in symbols:
            task = self.process_symbol_optimized(symbol, **kwargs)
            tasks.append(task)
        
        # –í–∏–∫–æ–Ω—É—î–º–æ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ –∑ –æ–±–º–µ–∂–µ–Ω–Ω—è–º
        semaphore = asyncio.Semaphore(3)  # –ú–∞–∫—Å–∏–º—É–º 3 —Å–∏–º–≤–æ–ª–∏ –æ–¥–Ω–æ—á–∞—Å–Ω–æ
        
        async def limited_process(task):
            async with semaphore:
                return await task
        
        limited_tasks = [limited_process(task) for task in tasks]
        results = await asyncio.gather(*limited_tasks, return_exceptions=True)
        
        # –û–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        successful = sum(1 for r in results if r is not None and not isinstance(r, Exception))
        failed = len(results) - successful
        
        logger.info(f"‚úÖ –ü–∞–∫–µ—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {successful} —É—Å–ø—ñ—à–Ω–æ, {failed} –∑ –ø–æ–º–∏–ª–∫–∞–º–∏")
        
        return results
    
    async def get_system_status(self):
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç—É—Å—É —Å–∏—Å—Ç–µ–º–∏"""
        return {
            'initialized': self.initialized,
            'gpu_available': self.gpu_available,
            'gpu_info': get_gpu_info() if self.gpu_available else None,
            'cache_stats': get_cache_info(),
            'worker_stats': ml_pipeline.worker_pool.get_stats() if ml_pipeline.worker_pool else None,
            'timestamp': datetime.now().isoformat()
        }
    
    async def cleanup(self):
        """–û—á–∏—â–µ–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤"""
        logger.info("üßπ –û—á–∏—â–µ–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤...")
        await shutdown_async_system()
        logger.info("‚úÖ –û—á–∏—â–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

# –ì–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä —Å–∏—Å—Ç–µ–º–∏
crypto_system = OptimizedCryptoMLSystem()

async def main():
    """–ì–æ–ª–æ–≤–Ω–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    parser = argparse.ArgumentParser(description="–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç")
    parser.add_argument("--symbol", type=str, default=SYMBOL, help="–¢–æ—Ä–≥–æ–≤–∞ –ø–∞—Ä–∞")
    parser.add_argument("--interval", type=str, default=INTERVAL, help="–Ü–Ω—Ç–µ—Ä–≤–∞–ª —á–∞—Å—É")
    parser.add_argument("--days_back", type=int, default=DAYS_BACK, help="–î–Ω—ñ–≤ —ñ—Å—Ç–æ—Ä—ñ—ó")
    parser.add_argument("--look_back", type=int, default=LOOK_BACK, help="–†–æ–∑–º—ñ—Ä –≤—ñ–∫–Ω–∞")
    parser.add_argument("--steps", type=int, default=STEPS, help="–ö—Ä–æ–∫—ñ–≤ –ø—Ä–æ–≥–Ω–æ–∑—É")
    parser.add_argument("--force_retrain", action="store_true", help="–ü—Ä–∏–º—É—Å–æ–≤–µ –ø–µ—Ä–µ—Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è")
    parser.add_argument("--batch", nargs="+", help="–ü–∞–∫–µ—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Å–∏–º–≤–æ–ª—ñ–≤")
    parser.add_argument("--status", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç–∏ —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º–∏")
    
    args = parser.parse_args()
    
    try:
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏
        await crypto_system.initialize()

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∑ Binance
        logger.info("‚è≥ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∑ Binance...")
        await save_ohlcv_to_db(db_manager, args.symbol, args.interval, days_back=args.days_back)
        logger.info("‚úÖ –î–∞–Ω—ñ –∑ Binance –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —É historical_data")

        if args.status:
            # –ü–æ–∫–∞–∑–∞—Ç–∏ —Å—Ç–∞—Ç—É—Å
            status = await crypto_system.get_system_status()
            logger.info(f"üìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º–∏: {status}")
            return
        
        if args.batch:
            # –ü–∞–∫–µ—Ç–Ω–∞ –æ–±—Ä–æ–±–∫–∞
            results = await crypto_system.batch_process_symbols(
                symbols=args.batch,
                interval=args.interval,
                days_back=args.days_back,
                look_back=args.look_back,
                steps=args.steps,
                force_retrain=args.force_retrain
            )
            
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ {args.batch[i]}: {result}")
                elif result:
                    logger.info(f"‚úÖ {args.batch[i]}: {result['predictions']}")
        else:
            # –û–±—Ä–æ–±–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª—É
            result = await crypto_system.process_symbol_optimized(
                symbol=args.symbol,
                interval=args.interval,
                days_back=args.days_back,
                look_back=args.look_back,
                steps=args.steps,
                force_retrain=args.force_retrain
            )
            
            if result:
                logger.info("üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è:")
                logger.info(f"   –°–∏–º–≤–æ–ª: {result['symbol']}")
                logger.info(f"   –û—Å—Ç–∞–Ω–Ω—è —Ü—ñ–Ω–∞: {result['last_price']:.2f}")
                logger.info(f"   –ü—Ä–æ–≥–Ω–æ–∑–∏: {[f'{p:.2f}' for p in result['predictions']]}")
                logger.info(f"   –ß–∞—Å –æ–±—Ä–æ–±–∫–∏: {result['processing_time']:.2f}s")
    
    except KeyboardInterrupt:
        logger.info("‚è∏Ô∏è –û—Ç—Ä–∏–º–∞–Ω–æ —Å–∏–≥–Ω–∞–ª –ø–µ—Ä–µ—Ä–∏–≤–∞–Ω–Ω—è")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}", exc_info=True)
    finally:
        await crypto_system.cleanup()

if __name__ == "__main__":
    # –Ü–º–ø–æ—Ä—Ç numpy –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤ —Ñ—É–Ω–∫—Ü—ñ—ó
    import numpy as np
    from sklearn.preprocessing import StandardScaler
    
    # –ó–∞–ø—É—Å–∫ –≥–æ–ª–æ–≤–Ω–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó
    asyncio.run(main())