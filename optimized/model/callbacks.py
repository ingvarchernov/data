"""
Custom Keras Callbacks

Callback'–∏ –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ:
- DatabaseHistoryCallback: –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó –≤ –ë–î
- DenormalizedMetricsCallback: –≤–∏–≤—ñ–¥ —Ä–µ–∞–ª—å–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫
"""

import logging
import numpy as np
from tensorflow import keras
from keras import callbacks

logger = logging.getLogger(__name__)


class DatabaseHistoryCallback(callbacks.Callback):
    """Callback –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –≤ –±–∞–∑—É –¥–∞–Ω–∏—Ö"""
    
    def __init__(self, db_engine, symbol_id: int, interval_id: int, fold: int = 1):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
        
        Args:
            db_engine: SQLAlchemy engine
            symbol_id: ID —Å–∏–º–≤–æ–ª—É –≤ –ë–î
            interval_id: ID —ñ–Ω—Ç–µ—Ä–≤–∞–ª—É –≤ –ë–î
            fold: –ù–æ–º–µ—Ä fold (–¥–ª—è cross-validation)
        """
        super().__init__()
        self.db_engine = db_engine
        self.symbol_id = symbol_id
        self.interval_id = interval_id
        self.fold = fold
    
    def on_epoch_end(self, epoch, logs=None):
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ –µ–ø–æ—Ö–∏ –≤ –ë–î"""
        if logs is None:
            return
        
        try:
            from sqlalchemy import text
            with self.db_engine.connect() as conn:
                conn.execute(text("""
                    INSERT INTO training_history 
                    (symbol_id, interval_id, fold, epoch, loss, mae, val_loss, val_mae, 
                     mape, val_mape, directional_accuracy, real_mae, real_mape)
                    VALUES (:symbol_id, :interval_id, :fold, :epoch, :loss, :mae, 
                            :val_loss, :val_mae, :mape, :val_mape, :directional_accuracy, 
                            :real_mae, :real_mape)
                    ON CONFLICT (symbol_id, interval_id, fold, epoch)
                    DO UPDATE SET
                        loss = EXCLUDED.loss,
                        mae = EXCLUDED.mae,
                        val_loss = EXCLUDED.val_loss,
                        val_mae = EXCLUDED.val_mae,
                        mape = EXCLUDED.mape,
                        val_mape = EXCLUDED.val_mape,
                        directional_accuracy = EXCLUDED.directional_accuracy,
                        real_mae = EXCLUDED.real_mae,
                        real_mape = EXCLUDED.real_mape
                """), {
                    'symbol_id': self.symbol_id,
                    'interval_id': self.interval_id,
                    'fold': self.fold,
                    'epoch': epoch + 1,  # epoch –ø–æ—á–∏–Ω–∞—î—Ç—å—Å—è –∑ 0, –∞–ª–µ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –∑ 1
                    'loss': float(logs.get('loss', 0)),
                    'mae': float(logs.get('mae', 0)),
                    'val_loss': float(logs.get('val_loss', 0)),
                    'val_mae': float(logs.get('val_mae', 0)),
                    'mape': float(logs.get('mape', 0)),
                    'val_mape': float(logs.get('val_mape', 0)),
                    'directional_accuracy': float(logs.get('directional_accuracy', 0)),
                    'real_mae': float(logs.get('real_mae', logs.get('mae', 0))),
                    'real_mape': float(logs.get('real_mape', logs.get('mape', 0)))
                })
                conn.commit()
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –ë–î: {e}")


class DenormalizedMetricsCallback(callbacks.Callback):
    """
    Callback –¥–ª—è –≤–∏–≤–æ–¥—É —Å–ø—Ä–æ—â–µ–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫
    
    –†–æ–∑—Ä–∞—Ö–æ–≤—É—î —Ç–∞ –≤–∏–≤–æ–¥–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —è–∫ —É –≤—ñ–¥—Å–æ—Ç–∫–æ–≤–∏—Ö –∑–º—ñ–Ω–∞—Ö, —Ç–∞–∫ —ñ –≤ —Ä–µ–∞–ª—å–Ω–∏—Ö —Ü—ñ–Ω–∞—Ö
    """
    
    def __init__(self, scaler=None, feature_index: int = None, X_val: np.ndarray = None, y_val: np.ndarray = None):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
        
        Args:
            scaler: Scaler –¥–ª—è –¥–µ–Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
            feature_index: –Ü–Ω–¥–µ–∫—Å —Ñ—ñ—á—ñ —Ü—ñ–Ω–∏ close
            X_val: Validation X data
            y_val: Validation y data
        """
        super().__init__()
        self.scaler = scaler
        self.feature_index = feature_index
        self.X_val = X_val
        self.y_val = y_val
    
    def on_epoch_end(self, epoch, logs=None):
        """–í–∏–≤—ñ–¥ –º–µ—Ç—Ä–∏–∫ –ø—ñ—Å–ª—è –µ–ø–æ—Ö–∏"""
        if logs is None:
            return
        
        try:
            # –û—Ç—Ä–∏–º—É—î–º–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö
            if self.X_val is not None and self.y_val is not None and self.scaler is not None:
                y_pred = self.model.predict(self.X_val, verbose=0).flatten()
                y_true = self.y_val  # –≤—ñ–¥—Å–æ—Ç–∫–æ–≤—ñ –∑–º—ñ–Ω–∏
                
                # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ä—ñ–≤–Ω—ñ –≤—ñ–¥—Å–æ—Ç–∫–æ–≤–∏—Ö –∑–º—ñ–Ω
                mae_norm = np.mean(np.abs(y_true - y_pred))
                mape_norm = np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + 1e-6))) * 100
                
                # Directional accuracy: –∑–Ω–∞–∫ –≤—ñ–¥—Å–æ—Ç–∫–æ–≤–∏—Ö –∑–º—ñ–Ω
                dir_acc = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100
                
                logger.info(f"üí∞ –ú–µ—Ç—Ä–∏–∫–∏ –≤—ñ–¥—Å–æ—Ç–∫–æ–≤–∏—Ö –∑–º—ñ–Ω (Epoch {epoch + 1}): "
                           f"MAE={mae_norm:.4f}, MAPE={mape_norm:.2f}%, –ù–∞–ø—Ä—è–º–æ–∫={dir_acc:.1f}%")
                
                # –†–µ–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏: –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –Ω–∞–∑–∞–¥ –¥–æ –∞–±—Å–æ–ª—é—Ç–Ω–∏—Ö —Ü—ñ–Ω
                current_prices = self.X_val[:, -1, self.feature_index].flatten()
                
                y_true_pct = y_true  # –≤—ñ–¥—Å–æ—Ç–∫–æ–≤—ñ –∑–º—ñ–Ω–∏
                y_pred_pct = y_pred  # –≤—ñ–¥—Å–æ—Ç–∫–æ–≤—ñ –∑–º—ñ–Ω–∏
                
                true_next_prices = current_prices * (1 + y_true_pct / 100)
                pred_next_prices = current_prices * (1 + y_pred_pct / 100)
                
                mae_real = np.mean(np.abs(true_next_prices - pred_next_prices))
                mape_real = np.mean(np.abs((true_next_prices - pred_next_prices) / (np.abs(true_next_prices) + 1e-6))) * 100
                
                logger.info(f"üíµ –†–µ–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ —Ü—ñ–Ω (Epoch {epoch + 1}): "
                           f"MAE={mae_real:.2f}, MAPE={mape_real:.2f}%, –ù–∞–ø—Ä—è–º–æ–∫={dir_acc:.1f}%")
                
                # –î–æ–¥–∞—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ –¥–æ logs –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –ë–î
                logs['mape'] = mape_real
                logs['val_mape'] = mape_real
                logs['directional_accuracy'] = dir_acc
                logs['real_mae'] = mae_real
                logs['real_mape'] = mape_real
            
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –º–µ—Ç—Ä–∏–∫: {e}")


__all__ = [
    'DatabaseHistoryCallback',
    'DenormalizedMetricsCallback',
]
